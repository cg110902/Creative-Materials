# ğŸ“‹ Claudeå†™ä½œæ‰§è¡ŒSOP v4.0 - åœºæ™¯ç±»å‹é©±åŠ¨ç³»ç»Ÿ

**è®¾è®¡å“²å­¦**ï¼šæ–‡å­¦æ€§ä¼˜å…ˆï¼ŒæŠ€æœ¯æŒ‡æ ‡æœåŠ¡äºå™äº‹ç›®æ ‡ã€‚

---

## Â§0 æ ¸å¿ƒå†™ä½œå“²å­¦ | ä»€ä¹ˆæ˜¯å¥½çš„å°è¯´

### 0.1 æ ¸å¿ƒåŸåˆ™

```python
# ä¼˜å…ˆçº§å®šä¹‰
PRIORITY_ORDER = [
    "è¯»è€…èƒ½å¦ç†è§£æ•…äº‹",      # P0 - æœ€é«˜ä¼˜å…ˆçº§
    "åœºæ™¯æ˜¯å¦è¾¾æˆæ–‡å­¦ç›®æ ‡",   # P1
    "è§’è‰²è¡Œä¸ºæ˜¯å¦åˆç†",       # P2
    "æŠ€æœ¯æŒ‡æ ‡æ˜¯å¦è¾¾æ ‡"        # P3 - æœ€ä½ä¼˜å…ˆçº§
]

# å½“æŠ€æœ¯æŒ‡æ ‡ä¸æ–‡å­¦æ€§å†²çªæ—¶
IF technical_metric_fails BUT literary_goal_achieved:
    ACCEPT_AND_DELIVER()  # æ–‡å­¦æ€§ä¼˜å…ˆ
ELSE IF technical_metric_passes BUT literary_goal_fails:
    REWRITE()  # æŠ€æœ¯æŒ‡æ ‡ä¸æ˜¯ç›®çš„
END IF
```

### 0.2 ä»€ä¹ˆæ˜¯å¥½åœºæ™¯

å¥½åœºæ™¯çš„ä¸‰ä¸ªæ ‡å‡†ï¼š
1. **è¯»è€…ä¸å›°æƒ‘**ï¼šçŸ¥é“WHO/WHERE/WHY NOWï¼Œç†è§£è§’è‰²åŠ¨æœº
2. **æœ‰ä¸œè¥¿å‘ç”Ÿ**ï¼šä¿¡æ¯/å…³ç³»/æƒ…ç»ªè‡³å°‘æœ‰ä¸€æ ·åœ¨å˜åŒ–
3. **ç•™ä¸‹å°è±¡**ï¼šå…·ä½“çš„ç”»é¢ã€å¯¹è¯æˆ–æƒ…ç»ªï¼Œè€ŒéæŠ½è±¡æ¦‚å¿µ

### 0.3 ä»€ä¹ˆæ˜¯å¥½å¯¹è¯

```python
FUNCTION IS_GOOD_DIALOGUE(dialogue):
    """å¥½å¯¹è¯çš„åˆ¤æ–­æ ‡å‡†"""
    
    # æ£€æŸ¥1ï¼šæ˜¯å¦æ¨è¿›å‰§æƒ…
    IF dialogue reveals_new_info OR changes_relationship OR triggers_action:
        RETURN TRUE
    END IF
    
    # æ£€æŸ¥2ï¼šæ˜¯å¦æ­ç¤ºè§’è‰²
    IF dialogue shows_personality OR shows_conflict OR shows_status:
        RETURN TRUE
    END IF
    
    # æ£€æŸ¥3ï¼šæ˜¯å¦åˆ¶é€ å¼ åŠ›
    IF dialogue creates_misunderstanding OR escalates_conflict OR plants_seed:
        RETURN TRUE
    END IF
    
    # å¦åˆ™æ˜¯æ— æ•ˆå¯¹è¯
    RETURN FALSE
END FUNCTION
```

### 0.4 çº¦æŸå±‚çº§

```python
CONSTRAINT_LEVELS = {
    "RED_LINE": {
        "priority": 0,
        "action_on_fail": "IMMEDIATE_STOP",
        "examples": ["OOC", "ä¸–ç•Œè§‚çŸ›ç›¾", "é€»è¾‘BUG"]
    },
    
    "LITERARY_GOAL": {
        "priority": 1,
        "action_on_fail": "REWRITE_SCENE",
        "examples": ["æ ¸å¿ƒä»»åŠ¡æœªå®Œæˆ", "è§’è‰²åŠ¨æœºä¸æ˜"]
    },
    
    "QUALITY_BASELINE": {
        "priority": 2,
        "action_on_fail": "TRY_FIX",
        "examples": ["å­—æ•°ä¸¥é‡ä¸è¶³", "ä¿¡æ¯å¯†åº¦è¿‡ä½"]
    },
    
    "POLISH_SUGGESTION": {
        "priority": 3,
        "action_on_fail": "LOG_WARNING",
        "examples": ["å¯¹è¯å æ¯”åä½", "æ®µè½è¿‡é•¿"]
    }
}
```

---

## Â§1 åœºæ™¯ç±»å‹ç³»ç»Ÿ | ä¸åŒåœºæ™¯ï¼Œä¸åŒå†™æ³•

### 1.1 åœºæ™¯ç±»å‹å®šä¹‰

```python
SCENE_TYPES = {
    "ç‹¬å¤„æ¢ç´¢": {
        "ç‰¹å¾": ["ä¸»è§’å•ç‹¬è¡ŒåŠ¨", "å‘ç°æ–°ä¿¡æ¯", "æ€è€ƒå†³ç­–"],
        "å¯¹è¯èŒƒå›´": [0.10, 0.25],  # å…è®¸ä½å¯¹è¯
        "å†…å¿ƒç‹¬ç™½èŒƒå›´": [0.20, 0.35],  # å…è®¸é«˜å†…å¿ƒæˆ
        "å†™ä½œé‡ç‚¹": "ç”»é¢æ„Ÿã€å‘ç°è¿‡ç¨‹ã€æ€è€ƒé€»è¾‘",
        "å…¸å‹ç»“æ„": "è§¦å‘ â†’ è§‚å¯Ÿ â†’ æ€è€ƒ â†’ å†³ç­–",
        
        # ========== æ–°å¢ï¼šç•ªèŒ„çº¦æŸ ==========
        "tomato_constraints": {
            "hook_interval": 500,  # æ¯500å­—ä¸€ä¸ªå°é’©å­ï¼ˆç‹¬å¤„å¯ä»¥ç¨é•¿ï¼‰
            "min_info_per_100": 1,  # æœ€ä½ä¿¡æ¯å¯†åº¦
            "max_boring_stretch": 400,  # æœ€å¤š400å­—æ— æ–°ä¿¡æ¯
            "must_have_discovery": TRUE,  # å¿…é¡»æœ‰å‘ç°/è¿›å±•
            "pace": "ä¸­é€Ÿ"  # èŠ‚å¥ï¼šæ…¢é€Ÿ/ä¸­é€Ÿ/å¿«é€Ÿ
        }
		
		
    },
    
    "åŒäººå¯¹è¯": {
        "ç‰¹å¾": ["ä¸¤ä¸ªè§’è‰²", "ä¿¡æ¯äº¤æ¢", "å…³ç³»å˜åŒ–"],
        "å¯¹è¯èŒƒå›´": [0.40, 0.60],
        "å†…å¿ƒç‹¬ç™½èŒƒå›´": [0.05, 0.15],
        "å†™ä½œé‡ç‚¹": "å¯¹è¯æ¨è¿›å‰§æƒ…ã€æ­ç¤ºå…³ç³»åŠ¨æ€",
        "å…¸å‹ç»“æ„": "å¼€åœº â†’ è¯•æ¢ â†’ äº¤é”‹ â†’ ç»“è®º",
        
        # ========== æ–°å¢ï¼šç•ªèŒ„çº¦æŸ ==========
        "tomato_constraints": {
            "hook_interval": 400,  # æ¯400å­—ä¸€ä¸ªå°é’©å­ï¼ˆå¯¹è¯æ›´ç´§å‡‘ï¼‰
            "min_info_per_100": 1.5,  # å¯¹è¯åœºæ™¯ä¿¡æ¯å¯†åº¦æ›´é«˜
            "max_boring_stretch": 300,  # å¯¹è¯ä¸èƒ½æ‹–æ²“
            "must_have_tension": TRUE,  # å¿…é¡»æœ‰å¼ åŠ›ï¼ˆè¯•æ¢/å†²çª/åè½¬ï¼‰
            "pace": "ä¸­é€Ÿ"
        }
    },
    
    "ç¾¤æˆå†²çª": {
        "ç‰¹å¾": ["3+è§’è‰²", "ç«‹åœºåˆ†æ­§", "å¤šæ–¹åšå¼ˆ"],
        "å¯¹è¯èŒƒå›´": [0.45, 0.65],
        "å†…å¿ƒç‹¬ç™½èŒƒå›´": [0.00, 0.10],
        "å†™ä½œé‡ç‚¹": "å¿«èŠ‚å¥ã€å¤šæ–¹ç«‹åœºã€å†²çªå‡çº§",
        "å…¸å‹ç»“æ„": "å¼•çˆ†ç‚¹ â†’ ç«™é˜Ÿ â†’ äº¤é”‹ â†’ æš‚æ—¶ç»“æœ",
        
        # ========== æ–°å¢ï¼šç•ªèŒ„çº¦æŸ ==========
        "tomato_constraints": {
            "hook_interval": 300,  # æ¯300å­—ä¸€ä¸ªå†²çªç‚¹
            "min_info_per_100": 2,  # é«˜å¯†åº¦ä¿¡æ¯
            "max_boring_stretch": 200,  # ç»ä¸æ‹–æ²“
            "must_have_escalation": TRUE,  # å¿…é¡»æœ‰å‡çº§
            "pace": "å¿«é€Ÿ"
        }
    },
    
    "å±æœºååº”": {
        "ç‰¹å¾": ["ç´§æ€¥æƒ…å†µ", "æœ¬èƒ½ååº”", "ç”Ÿæ­»æ”¸å…³"],
        "å¯¹è¯èŒƒå›´": [0.15, 0.30],  # å±æœºæ—¶è¯å°‘
        "å†…å¿ƒç‹¬ç™½èŒƒå›´": [0.05, 0.15],
        "å†™ä½œé‡ç‚¹": "ç”Ÿç†ååº”ã€æœ¬èƒ½è¡ŒåŠ¨ã€ç´§å¼ æ„Ÿ",
        "å…¸å‹ç»“æ„": "å±æœº â†’ ç”Ÿç†ååº” â†’ åº”å¯¹è¡ŒåŠ¨ â†’ æš‚æ—¶å®‰å…¨",
        
        # ========== æ–°å¢ï¼šç•ªèŒ„çº¦æŸ ==========
        "tomato_constraints": {
            "hook_interval": 250,  # æ¯250å­—ä¸€ä¸ªå±æœºç‚¹
            "min_info_per_100": 1.5,  # å¿«èŠ‚å¥ä¸‹çš„é«˜å¯†åº¦
            "max_boring_stretch": 150,  # æçŸ­
            "must_have_physiology": TRUE,  # å¿…é¡»æœ‰ç”Ÿç†ååº”
            "pace": "å¿«é€Ÿ"
        }
    },
    
    "æƒ…æ„Ÿè½¬æŠ˜": {
        "ç‰¹å¾": ["æƒ…ç»ªå‰§å˜", "è®¤çŸ¥é¢ è¦†", "å…³ç³»è´¨å˜"],
        "å¯¹è¯èŒƒå›´": [0.25, 0.40],
        "å†…å¿ƒç‹¬ç™½èŒƒå›´": [0.15, 0.30],
        "å†™ä½œé‡ç‚¹": "æƒ…ç»ªé€’è¿›ã€è®¤çŸ¥å†²çªã€è½¬æŠ˜ç‚¹",
        "å…¸å‹ç»“æ„": "è§¦å‘ â†’ æŠ—æ‹’ â†’ å´©æºƒ â†’ æ¥å—",
        
        # ========== æ–°å¢ï¼šç•ªèŒ„çº¦æŸ ==========
        "tomato_constraints": {
            "hook_interval": 400,  # æ¯400å­—ä¸€ä¸ªæƒ…ç»ªç‚¹
            "min_info_per_100": 1.2,  # ä¸­ç­‰å¯†åº¦
            "max_boring_stretch": 350,
            "must_have_turn": TRUE,  # å¿…é¡»æœ‰æƒ…ç»ªè½¬æŠ˜
            "pace": "ä¸­é€Ÿ"
        }
    }
}
```

### 1.2 åœºæ™¯ç±»å‹è¯†åˆ«

```python

FUNCTION IDENTIFY_SCENE_TYPE(scene_description, parsed_data):
    """
    æ ¹æ®åœºæ™¯æè¿°è‡ªåŠ¨è¯†åˆ«ç±»å‹
    
    è¯†åˆ«é€»è¾‘ï¼ˆæ”¹è¿›ç‰ˆï¼‰ï¼š
    1. æå–åœºæ™¯æ ¸å¿ƒåŠ¨è¯å’Œç›®æ ‡
    2. è§’è‰²æ•°é‡ + åœºæ™¯ç›®æ ‡ â†’ ç»¼åˆåˆ¤æ–­
    3. ç‰¹æ®Šåœºæ™¯ä¼˜å…ˆè¯†åˆ«ï¼ˆå±æœºã€æƒ…æ„Ÿè½¬æŠ˜ï¼‰
    """
    
    # æå–åŸºç¡€ä¿¡æ¯
    character_count = COUNT_CHARACTERS_IN_SCENE(scene_description)
    core_verbs = EXTRACT_CORE_VERBS(scene_description)
    scene_goal = scene_description.LOWER()  # ç®€åŒ–ï¼šç›´æ¥ç”¨æè¿°æ–‡æœ¬
    
    # ========== ä¼˜å…ˆçº§1ï¼šå±æœºåœºæ™¯è¯†åˆ« ==========
    crisis_keywords = ["å±æœº", "æ”»å‡»", "é€ƒè·‘", "æˆ˜æ–—", "å—ä¼¤", "è¿½æ€", "å¦–åŒ–"]
    IF ANY(keyword IN scene_goal FOR keyword IN crisis_keywords):
        RETURN "å±æœºååº”"
    END IF
    
    # ========== ä¼˜å…ˆçº§2ï¼šæƒ…æ„Ÿè½¬æŠ˜è¯†åˆ« ==========
    emotion_keywords = ["å´©æºƒ", "å†³è£‚", "é†’æ‚Ÿ", "è®¤çŸ¥", "é¢†æ‚Ÿ", "æ¥å—", "æ”¾å¼ƒ"]
    emotion_intensity = GET_EMOTION_INTENSITY(scene_description, parsed_data)
    
    IF ANY(keyword IN scene_goal FOR keyword IN emotion_keywords) OR emotion_intensity > 70:
        RETURN "æƒ…æ„Ÿè½¬æŠ˜"
    END IF
    
    # ========== ä¼˜å…ˆçº§3ï¼šæ ¹æ®è§’è‰²æ•°é‡åˆæ­¥åˆ†ç±» ==========
    IF character_count == 1:
        # å•è§’è‰²åœºæ™¯ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å‘ç°/æ¢ç´¢
        discovery_keywords = ["å‘ç°", "æ‰¾åˆ°", "çœ‹åˆ°", "æ³¨æ„åˆ°", "æ¡åˆ°", "å¾—åˆ°"]
        
        IF ANY(keyword IN core_verbs FOR keyword IN discovery_keywords):
            RETURN "ç‹¬å¤„æ¢ç´¢"
        ELSE:
            # æ²¡æœ‰æ˜æ˜¾å‘ç°ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯ä¿®ç‚¼/æ€è€ƒç±»ï¼ˆä½å¼ åŠ›ï¼‰
            routine_keywords = ["ä¿®ç‚¼", "æ‰“å", "ä¼‘æ¯", "æ•´ç†", "å›å¿†"]
            
            IF ANY(keyword IN scene_goal FOR keyword IN routine_keywords):
                PRINT "[WARN] åœºæ™¯ä¼¼ä¹æ˜¯ä½å¼ åŠ›æ—¥å¸¸ï¼Œå»ºè®®å‹ç¼©æˆ–åˆå¹¶åˆ°å…¶ä»–åœºæ™¯"
                RETURN "ç‹¬å¤„æ¢ç´¢"  # é»˜è®¤å½’ç±»
            ELSE:
                RETURN "ç‹¬å¤„æ¢ç´¢"
            END IF
        END IF
    
    ELSE IF character_count == 2:
        # åŒè§’è‰²åœºæ™¯ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å†²çª
        conflict_keywords = ["å†²çª", "äº‰æ‰§", "è´¨é—®", "æ‹’ç»", "å¯¹æŠ—", "è¯•æ¢"]
        
        IF ANY(keyword IN scene_goal FOR keyword IN conflict_keywords):
            RETURN "åŒäººå¯¹è¯"  # æœ‰å†²çªçš„åŒäººæˆ
        ELSE:
            # æ— å†²çªï¼šæ£€æŸ¥æ˜¯å¦æ˜¯ä¿¡æ¯äº¤æ¢
            info_keywords = ["è¯¢é—®", "å‘Šè¯‰", "è§£é‡Š", "äº¤ä»£", "å•†é‡"]
            
            IF ANY(keyword IN scene_goal FOR keyword IN info_keywords):
                RETURN "åŒäººå¯¹è¯"
            ELSE:
                # éƒ½ä¸æ˜¯ï¼šé»˜è®¤åŒäººå¯¹è¯
                RETURN "åŒäººå¯¹è¯"
            END IF
        END IF
    
    ELSE:  # 3+è§’è‰²
        # å¤šè§’è‰²åœºæ™¯ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯ç¾¤æˆå†²çª
        group_conflict_keywords = ["äº‰è®º", "ç«™é˜Ÿ", "å¯¹å³™", "å¤šæ–¹", "å›´æ”»"]
        
        IF ANY(keyword IN scene_goal FOR keyword IN group_conflict_keywords):
            RETURN "ç¾¤æˆå†²çª"
        ELSE:
            # ä¸æ˜¯å†²çªï¼šå¯èƒ½æ˜¯ç¾¤ä½“å¯¹è¯ï¼ˆé™çº§ä¸ºåŒäººå¯¹è¯ï¼‰
            PRINT f"[INFO] åœºæ™¯æœ‰{character_count}ä¸ªè§’è‰²ï¼Œä½†æ— æ˜æ˜¾å†²çªï¼Œå½’ç±»ä¸ºåŒäººå¯¹è¯"
            RETURN "åŒäººå¯¹è¯"
        END IF
    END IF
END FUNCTION

FUNCTION EXTRACT_CORE_VERBS(text):
    """æå–åœºæ™¯æè¿°ä¸­çš„æ ¸å¿ƒåŠ¨è¯"""
    
    # ç®€åŒ–å®ç°ï¼šæå–å¸¸è§åŠ¨è¯
    common_verbs = [
        "å‘ç°", "æ‰¾åˆ°", "çœ‹åˆ°", "é‡åˆ°", "å¾—åˆ°", "å¤±å»",
        "è¯¢é—®", "å‘Šè¯‰", "è§£é‡Š", "äº‰è®º", "æ‹’ç»", "åŒæ„",
        "æ”»å‡»", "é€ƒè·‘", "æˆ˜æ–—", "ä¿®ç‚¼", "æ€è€ƒ", "å†³å®š"
    ]
    
    found_verbs = []
    FOR verb IN common_verbs:
        IF verb IN text:
            found_verbs.APPEND(verb)
        END IF
    END FOR
    
    RETURN found_verbs
END FUNCTION

```

---

## Â§2 åœºæ™¯è§„åˆ’å¼•æ“ | ä»èƒ¶å›Šåˆ°å†™ä½œè®¡åˆ’

### 2.1 èƒ¶å›Šè§£æï¼ˆä¿ç•™v3.1é€»è¾‘ï¼Œç®€åŒ–ä»£ç ï¼‰

```python
FUNCTION PARSE_CAPSULE(CAPSULE):
    """è§£æä¿¡æ¯èƒ¶å›Šï¼ˆå‚è€ƒv3.1å®ç°ï¼Œæ­¤å¤„ç®€åŒ–ï¼‰"""
    parsed = EXTRACT_ALL_SECTIONS(CAPSULE)  # æå–Â§1-Â§19
    VALIDATE_REQUIRED_FIELDS(parsed)  # æ ¡éªŒå¿…å¡«é¡¹
    RETURN parsed
END FUNCTION
```

### 2.2 åœºæ™¯è§„åˆ’æµç¨‹

```python
FUNCTION PLAN_CHAPTER(parsed_data):
    """
    ç« èŠ‚è§„åˆ’ï¼šä»èƒ¶å›Šç”Ÿæˆåœºæ™¯è®¡åˆ’
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    - ä¸å†ç”Ÿæˆ"ä»»åŠ¡æ¸…å•"
    - æ”¹ä¸ºç”Ÿæˆ"æ–‡å­¦ç›®æ ‡+åœºæ™¯ç±»å‹+çº¦æŸèŒƒå›´"
    """
    
    plan = {
        "scenes": [],
        "total_budget": parsed_data.meta.GET("word_count_target", 2000)
    }
    
    # STEP 1: æ¨æ–­åœºæ™¯æ•°é‡å’Œè¾¹ç•Œ
    scene_boundaries = INFER_SCENE_BOUNDARIES(parsed_data)
    
    # STEP 2: ä¸ºæ¯ä¸ªåœºæ™¯è®¾å®šç›®æ ‡
    FOR scene_idx, boundary IN ENUMERATE(scene_boundaries):
        scene_plan = {
            "scene_idx": scene_idx + 1,
            "type": NULL,  # å¾…è¯†åˆ«
            "literary_goal": "",  # æ–‡å­¦ç›®æ ‡
            "constraints": {},  # åŠ¨æ€çº¦æŸ
            "budget": 0,  # å­—æ•°é¢„ç®—
            "must_include": [],  # å¿…é¡»åŒ…å«çš„å…ƒç´ 
            "avoid": []  # å¿…é¡»é¿å…çš„å…ƒç´ 
        }
        
        # 2.1 è¯†åˆ«åœºæ™¯ç±»å‹
        scene_plan.type = IDENTIFY_SCENE_TYPE(boundary.description, parsed_data)
        
        # 2.2 è®¾å®šæ–‡å­¦ç›®æ ‡
        scene_plan.literary_goal = EXTRACT_LITERARY_GOAL(boundary, parsed_data)
        
        # 2.3 ç”ŸæˆåŠ¨æ€çº¦æŸ
        scene_plan.constraints = GENERATE_DYNAMIC_CONSTRAINTS(
            scene_plan.type, 
            parsed_data
        )
        
        # 2.4 åˆ†é…å­—æ•°é¢„ç®—
        scene_plan.budget = ALLOCATE_SCENE_BUDGET(
            scene_plan, 
            plan.total_budget,
            scene_boundaries
        )
        
        # 2.5 æå–å¿…é¡»/ç¦æ­¢å…ƒç´ 
        scene_plan.must_include = EXTRACT_MUST_ELEMENTS(boundary, parsed_data)
        scene_plan.avoid = EXTRACT_AVOID_ELEMENTS(boundary, parsed_data)
        
        plan.scenes.APPEND(scene_plan)
    END FOR
	
	
	    # ========== æ–°å¢ï¼šçˆ½ç‚¹è§„åˆ’ï¼ˆç•ªèŒ„å¿…å¤‡ï¼‰==========
		total_words = plan.total_budget
		
		# ä¸å†æŒ‰å­—æ•°è®¡ç®—çˆ½ç‚¹æ•°é‡ï¼Œæ”¹ä¸ºåˆ†æå‰§æƒ…å¼ åŠ›
		plan.cool_point_plan = PLAN_COOL_POINTS_BY_TENSION(
			plan.scenes, 
			parsed_data
		)
		
		IF LENGTH(plan.cool_point_plan) > 0:
			PRINT f"[PLAN] æ ¹æ®å‰§æƒ…å¼ åŠ›è§„åˆ’çˆ½ç‚¹æ•°é‡: {LENGTH(plan.cool_point_plan)}"
			FOR scene_idx, cool_type IN plan.cool_point_plan.ITEMS():
				PRINT f"  - åœºæ™¯{scene_idx}: {cool_type}"
			END FOR
		ELSE:
			PRINT "[PLAN] æœ¬ç« å‰§æƒ…å¼ åŠ›ä¸è¶³ï¼Œä¸å¼ºåˆ¶è§„åˆ’çˆ½ç‚¹"
		END IF
		
    
    
    RETURN plan
END FUNCTION


# ========== æ–°å¢å‡½æ•° ==========


FUNCTION PLAN_COOL_POINTS_BY_TENSION(scenes, parsed_data):
    """
    æ ¹æ®å‰§æƒ…å¼ åŠ›è§„åˆ’çˆ½ç‚¹ï¼ˆè€Œéå­—æ•°ï¼‰
    
    åŸåˆ™ï¼š
    1. åˆ†ææ¯ä¸ªåœºæ™¯çš„å‰§æƒ…å¼ åŠ›å€¼
    2. åœ¨å¼ åŠ›å³°å€¼å¤„è§„åˆ’çˆ½ç‚¹
    3. å¦‚æœæ²¡æœ‰é«˜å¼ åŠ›åœºæ™¯ï¼Œä¸å¼ºæ±‚çˆ½ç‚¹
    4. çˆ½ç‚¹ç±»å‹åŒ¹é…åœºæ™¯ç±»å‹
    """
    
    cool_plan = {}
    
    # Step 1: è®¡ç®—æ¯ä¸ªåœºæ™¯çš„å¼ åŠ›å€¼
    tension_scores = []
    FOR scene IN scenes:
        tension = CALCULATE_SCENE_TENSION(scene, parsed_data)
        tension_scores.APPEND({
            "scene_idx": scene.scene_idx,
            "tension": tension,
            "type": scene.type,
            "goal": scene.literary_goal
        })
    END FOR
    
    # Step 2: æ‰¾åˆ°å¼ åŠ›å³°å€¼åœºæ™¯ï¼ˆtension > 70ï¼‰
    peak_scenes = FILTER(tension_scores, lambda s: s.tension > 70)
    
    IF LENGTH(peak_scenes) == 0:
        # æ²¡æœ‰é«˜å¼ åŠ›åœºæ™¯ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ä¸­ç­‰å¼ åŠ›ï¼ˆ50-70ï¼‰
        medium_scenes = FILTER(tension_scores, lambda s: 50 < s.tension <= 70)
        
        IF LENGTH(medium_scenes) > 0:
            # åœ¨æœ€é«˜çš„ä¸­ç­‰å¼ åŠ›åœºæ™¯å®‰æ’ä¸€ä¸ªçˆ½ç‚¹
            highest = MAX(medium_scenes, key=lambda s: s.tension)
            cool_plan[highest.scene_idx] = SELECT_COOL_TYPE_FOR_SCENE(highest)
            PRINT f"[COOL] ä¸­ç­‰å¼ åŠ›åœºæ™¯{highest.scene_idx}ï¼ˆå¼ åŠ›{highest.tension}ï¼‰ï¼Œå®‰æ’çˆ½ç‚¹"
        ELSE:
            # å®Œå…¨æ²¡æœ‰å¼ åŠ›ï¼Œä¸å®‰æ’çˆ½ç‚¹
            PRINT "[COOL] æœ¬ç« æ•´ä½“å¼ åŠ›ä¸è¶³ï¼ˆ<50ï¼‰ï¼Œä¸å®‰æ’çˆ½ç‚¹"
        END IF
        
        RETURN cool_plan
    END IF
    
    # Step 3: åœ¨å³°å€¼åœºæ™¯å®‰æ’çˆ½ç‚¹ï¼ˆæœ€å¤šä¸è¶…è¿‡3ä¸ªï¼‰
    peak_scenes = SORT(peak_scenes, key=lambda s: s.tension, reverse=TRUE)
    selected_scenes = peak_scenes[:MIN(3, LENGTH(peak_scenes))]
    
    FOR scene IN selected_scenes:
        cool_type = SELECT_COOL_TYPE_FOR_SCENE(scene)
        cool_plan[scene.scene_idx] = cool_type
        PRINT f"[COOL] é«˜å¼ åŠ›åœºæ™¯{scene.scene_idx}ï¼ˆå¼ åŠ›{scene.tension}ï¼‰ï¼Œå®‰æ’{cool_type}"
    END FOR
    
    RETURN cool_plan
END FUNCTION

FUNCTION CALCULATE_SCENE_TENSION(scene, parsed_data):
    """
    è®¡ç®—åœºæ™¯çš„å‰§æƒ…å¼ åŠ›å€¼ï¼ˆ0-100ï¼‰
    
    å¼ åŠ›æ¥æºï¼š
    - å†²çªå¼ºåº¦
    - åˆ©ç›Šç›¸å…³åº¦
    - æƒ…ç»ªæ¿€çƒˆç¨‹åº¦
    - æ—¶é—´å‹åŠ›
    """
    
    tension = 0
    
    # å› ç´ 1ï¼šåœºæ™¯ç±»å‹åŸºç¡€å¼ åŠ›
    type_base_tension = {
        "ç‹¬å¤„æ¢ç´¢": 30,
        "åŒäººå¯¹è¯": 40,
        "ç¾¤æˆå†²çª": 70,
        "å±æœºååº”": 85,
        "æƒ…æ„Ÿè½¬æŠ˜": 60
    }
    tension += type_base_tension.GET(scene.type, 30)
    
    # å› ç´ 2ï¼šåœºæ™¯ç›®æ ‡ä¸­çš„å†²çªå…³é”®è¯
    goal = scene.literary_goal.LOWER()
    conflict_keywords = ["å†²çª", "å¯¹æŠ—", "å±æœº", "å¤±è´¥", "æŸå¤±", "æ­ç©¿", "åè½¬"]
    conflict_count = SUM([1 FOR keyword IN conflict_keywords IF keyword IN goal])
    tension += conflict_count * 10
    
    # å› ç´ 3ï¼šæƒ…ç»ªå¼ºåº¦ï¼ˆä»èƒ¶å›ŠÂ§8æå–ï¼‰
    IF "emotions" IN parsed_data:
        emotion_intensity = parsed_data.emotions.GET("intensity", 50)
        tension += (emotion_intensity - 50) * 0.3  # å½’ä¸€åŒ–å½±å“
    END IF
    
    # å› ç´ 4ï¼šæ˜¯å¦æ¶‰åŠæ ¸å¿ƒä»»åŠ¡
    IF "core_mission" IN scene.literary_goal:
        tension += 15
    END IF
    
    # å› ç´ 5ï¼šæ˜¯å¦æœ‰"å¿…é¡»åŒ…å«"çš„é«˜å¼ åŠ›å…ƒç´ 
    IF "danger" IN scene.must_include:
        tension += 20
    END IF
    
    RETURN CLAMP(tension, 0, 100)
END FUNCTION

FUNCTION SELECT_COOL_TYPE_FOR_SCENE(scene):
    """æ ¹æ®åœºæ™¯ç±»å‹å’Œä½ç½®é€‰æ‹©çˆ½ç‚¹ç±»å‹"""
    
    scene_type = scene.type
    goal = scene.goal.LOWER()
    
    # è§„åˆ™1ï¼šæ ¹æ®åœºæ™¯ç±»å‹
    IF scene_type == "ç¾¤æˆå†²çª":
        IF "æ­ç©¿" IN goal OR "æ‰“è„¸" IN goal:
            RETURN "æ‰“è„¸çˆ½"
        ELSE:
            RETURN "è£…é€¼çˆ½"
        END IF
    
    ELSE IF scene_type == "å±æœºååº”":
        RETURN "åæ€çˆ½"
    
    ELSE IF scene_type == "æƒ…æ„Ÿè½¬æŠ˜":
        RETURN "è®¤çŸ¥çˆ½"
    
    ELSE IF scene_type == "åŒäººå¯¹è¯":
        IF "äº¤æ˜“" IN goal OR "è°ˆåˆ¤" IN goal:
            RETURN "è£…é€¼çˆ½"
        ELSE:
            RETURN "æ‰“è„¸çˆ½"
        END IF
    
    ELSE:
        # é»˜è®¤ï¼šæ ¹æ®å‰§æƒ…é˜¶æ®µ
        IF scene.scene_idx <= 2:
            RETURN "æ‰“è„¸çˆ½"
        ELSE:
            RETURN RANDOM_CHOICE(["è£…é€¼çˆ½", "åæ€çˆ½"])
        END IF
    END IF
END FUNCTION

FUNCTION PLAN_COOL_POINTS(scenes, count, parsed_data):
    """
    è§„åˆ’çˆ½ç‚¹åˆ†å¸ƒï¼ˆç•ªèŒ„å°è¯´æ ¸å¿ƒï¼‰
    
    è§„åˆ™ï¼š
    1. ä¼˜å…ˆåˆ†é…åˆ°"åŒäººå¯¹è¯"æˆ–"ç¾¤æˆå†²çª"åœºæ™¯
    2. é¿å…è¿ç»­ä¸¤ä¸ªåœºæ™¯éƒ½æ˜¯çˆ½ç‚¹ï¼ˆä¼šè…»ï¼‰
    3. å¿…é¡»åœ¨ååŠéƒ¨åˆ†æœ‰è‡³å°‘ä¸€ä¸ªçˆ½ç‚¹
    """
    
    cool_types = ["æ‰“è„¸çˆ½", "è£…é€¼çˆ½", "å¤ä»‡çˆ½", "å‡çº§çˆ½", "åæ€çˆ½"]
    cool_plan = {}
    
    # å€™é€‰åœºæ™¯ï¼šå¯¹è¯/å†²çªç±»å‹ä¼˜å…ˆ
    candidates = []
    FOR i, scene IN ENUMERATE(scenes):
        IF scene.type IN ["åŒäººå¯¹è¯", "ç¾¤æˆå†²çª", "æƒ…æ„Ÿè½¬æŠ˜"]:
            candidates.APPEND(i + 1)  # scene_idxä»1å¼€å§‹
        END IF
    END FOR
    
    # å¦‚æœå€™é€‰åœºæ™¯ä¸è¶³ï¼Œè¡¥å……å…¶ä»–åœºæ™¯
    IF LENGTH(candidates) < count:
        FOR i, scene IN ENUMERATE(scenes):
            IF (i + 1) NOT IN candidates:
                candidates.APPEND(i + 1)
            END IF
        END FOR
    END IF
    
    # å‡åŒ€åˆ†å¸ƒçˆ½ç‚¹
    selected = DISTRIBUTE_EVENLY(candidates, count)
    
    # åˆ†é…çˆ½ç‚¹ç±»å‹
    FOR i, scene_idx IN ENUMERATE(selected):
        position_ratio = scene_idx / LENGTH(scenes)
        
        IF position_ratio < 0.3:
            cool_plan[scene_idx] = RANDOM_CHOICE(["æ‰“è„¸çˆ½", "è£…é€¼çˆ½"])
        ELSE IF position_ratio < 0.7:
            cool_plan[scene_idx] = RANDOM_CHOICE(["è£…é€¼çˆ½", "å¤ä»‡çˆ½"])
        ELSE:
            cool_plan[scene_idx] = RANDOM_CHOICE(["å‡çº§çˆ½", "åæ€çˆ½"])
        END IF
    END FOR
    
    RETURN cool_plan
END FUNCTION

```

### 2.3 åŠ¨æ€çº¦æŸç”Ÿæˆ

```python
FUNCTION GENERATE_DYNAMIC_CONSTRAINTS(scene_type, parsed_data):
    """
    æ ¹æ®åœºæ™¯ç±»å‹ç”ŸæˆåŠ¨æ€çº¦æŸ
    
    æ ¸å¿ƒç†å¿µï¼šçº¦æŸæ˜¯ä¸ºæ–‡å­¦ç›®æ ‡æœåŠ¡çš„
    """
    base_constraints = SCENE_TYPES[scene_type]
    
    constraints = {
        "dialogue_ratio": base_constraints.å¯¹è¯èŒƒå›´,
        "inner_monologue_ratio": base_constraints.å†…å¿ƒç‹¬ç™½èŒƒå›´,
        "writing_focus": base_constraints.å†™ä½œé‡ç‚¹,
        "typical_structure": base_constraints.å…¸å‹ç»“æ„,
        
        # åŠ¨æ€è°ƒæ•´éƒ¨åˆ†
        "allow_low_dialogue": scene_type IN ["ç‹¬å¤„æ¢ç´¢", "å±æœºååº”"],
        "allow_high_inner": scene_type IN ["ç‹¬å¤„æ¢ç´¢", "æƒ…æ„Ÿè½¬æŠ˜"],
        "prioritize_pace": scene_type IN ["ç¾¤æˆå†²çª", "å±æœºååº”"]
    }
    
    # æ ¹æ®ç« èŠ‚æ•´ä½“æƒ…ç»ªè°ƒæ•´
    IF "emotions" IN parsed_data:
        emotion_intensity = parsed_data.emotions.GET("intensity", 50)
        
        IF emotion_intensity > 70:
            # é«˜æƒ…ç»ªåœºæ™¯ï¼šå‹ç¼©å†…å¿ƒæˆï¼Œå¢åŠ è¡ŒåŠ¨
            constraints.inner_monologue_ratio = [
                constraints.inner_monologue_ratio[0] * 0.7,
                constraints.inner_monologue_ratio[1] * 0.7
            ]
        END IF
    END IF
    
    RETURN constraints
END FUNCTION
```

### 2.4 æ–‡å­¦ç›®æ ‡æå–

```python
FUNCTION EXTRACT_LITERARY_GOAL(boundary, parsed_data):
    """
    ä»åœºæ™¯æè¿°æå–æ–‡å­¦ç›®æ ‡
    
    ç¤ºä¾‹ï¼š
    - "è¯»è€…è¦ç†è§£ä¸»è§’ä¸ºä»€ä¹ˆå†’é™©"
    - "å±•ç¤ºä¸»è§’çš„å¼ºè¿«ç—‡äººè®¾"
    - "æ¨è¿›å…³ç³»ä»é™Œç”Ÿåˆ°è¯•æ¢åˆä½œ"
    """
    
    # ä»æ ¸å¿ƒä»»åŠ¡æå–
    IF "core_mission" IN parsed_data.goals:
        mission = parsed_data.goals.core_mission
        RETURN f"å®Œæˆä»»åŠ¡ï¼š{mission}"
    END IF
    
    # ä»æƒ…æ„Ÿç›®æ ‡æå–
    IF "emotional_goal" IN parsed_data.goals:
        RETURN parsed_data.goals.emotional_goal
    END IF
    
    # é»˜è®¤ç›®æ ‡
    RETURN "æ¨è¿›å‰§æƒ…ï¼Œæä¾›æ–°ä¿¡æ¯"
END FUNCTION
```

---

## Â§3 åœºæ™¯å†™ä½œæ¨¡å¼åº“ | å¯å¤ç”¨çš„å†™ä½œæ¨¡æ¿

## Â§3.0 åŸºç¡€ç”Ÿæˆå‡½æ•°åº“ | å¯å¤ç”¨çš„å†™ä½œåŸå­

### 3.0.1 è§¦å‘ç±»å‡½æ•°
```python
FUNCTION GENERATE_DISCOVERY_TRIGGER(item, protagonist, environment, style="minimal"):
    """
    ç”Ÿæˆå‘ç°åœºæ™¯çš„è§¦å‘äº‹ä»¶
    
    å‚æ•°ï¼š
    - item: è¢«å‘ç°çš„ç‰©å“/ç°è±¡
    - protagonist: ä¸»è§’ä¿¡æ¯
    - environment: ç¯å¢ƒä¿¡æ¯
    - style: "minimal"ç®€çŸ­ / "detailed"è¯¦ç»†
    """
    
    IF style == "minimal":
        # ç®€çŸ­è§¦å‘ï¼šç›´æ¥èšç„¦å¼‚å¸¸
        templates = [
            f"{item.name}å°±åœ¨é‚£é‡Œã€‚",
            f"{protagonist.name}åœä¸‹äº†åŠ¨ä½œã€‚",
            f"ä¸å¯¹åŠ²ã€‚"
        ]
        RETURN RANDOM_CHOICE(templates)
    
    ELSE IF style == "detailed":
        # è¯¦ç»†è§¦å‘ï¼šç¯å¢ƒ+å¼‚å¸¸
        env_detail = GENERATE_ENVIRONMENT_SNAPSHOT(environment)
        trigger = f"{env_detail}\n\n{protagonist.name}æ³¨æ„åˆ°äº†{item.name}ã€‚"
        RETURN trigger
    
    ELSE:
        RETURN f"{protagonist.name}å‘ç°äº†{item.name}ã€‚"
    END IF
END FUNCTION

FUNCTION GENERATE_ENVIRONMENT_SNAPSHOT(environment):
    """ç”Ÿæˆç¯å¢ƒå¿«ç…§ï¼ˆä¸€å¥è¯å®šä½æ—¶ç©ºï¼‰"""
    
    time = environment.GET("time", "")
    location = environment.GET("location", "")
    atmosphere = environment.GET("atmosphere", "")
    
    IF time AND location:
        RETURN f"{time}ï¼Œ{location}"
    ELSE IF location:
        RETURN location
    ELSE:
        RETURN "è¿™é‡Œ"
    END IF
END FUNCTION
```

### 3.0.2 è§‚å¯Ÿç±»å‡½æ•°
```python
FUNCTION GENERATE_OBSERVATION_SEQUENCE(target, sensory_focus, detail_level="medium", avoid_telling=TRUE):
    """
    ç”Ÿæˆè§‚å¯Ÿåºåˆ—ï¼ˆæ„Ÿå®˜ç»†èŠ‚ï¼‰
    
    å‚æ•°ï¼š
    - target: è§‚å¯Ÿå¯¹è±¡
    - sensory_focus: ["visual", "tactile", "auditory"] æ„Ÿå®˜ç±»å‹
    - detail_level: "low"ç®€ç•¥ / "medium"ä¸­ç­‰ / "high"è¯¦ç»†
    - avoid_telling: æ˜¯å¦é¿å…Tellå¼æå†™
    """
    
    observation = ""
    
    # æŒ‰æ„Ÿå®˜ç±»å‹ç”Ÿæˆç»†èŠ‚
    FOR sense IN sensory_focus:
        detail = GENERATE_SENSORY_DETAIL(target, sense, detail_level)
        
        IF avoid_telling:
            # é¿å…"ä»–çœ‹åˆ°Xå¾ˆY"çš„Tellå¼
            detail = CONVERT_TO_SHOW_STYLE(detail)
        END IF
        
        observation += detail
        
        IF detail_level == "high":
            observation += "\n\n"  # è¯¦ç»†æ¨¡å¼åˆ†æ®µ
        ELSE:
            observation += "ï¼Œ"  # ç®€ç•¥æ¨¡å¼é€—å·è¿æ¥
        END IF
    END FOR
    
    RETURN observation.TRIM()
END FUNCTION

FUNCTION GENERATE_SENSORY_DETAIL(target, sense_type, detail_level):
    """ç”Ÿæˆå•ä¸ªæ„Ÿå®˜ç»†èŠ‚"""
    
    # å¦‚æœèƒ¶å›Šä¸­æœ‰æ„Ÿå®˜ç´ æï¼Œä¼˜å…ˆä½¿ç”¨
    IF target.name IN GLOBAL_SENSORY_LIBRARY:
        materials = GLOBAL_SENSORY_LIBRARY[target.name]
        
        IF sense_type IN materials:
            detail = RANDOM_CHOICE(materials[sense_type])
            RETURN detail
        END IF
    END IF
    
    # å¦åˆ™ç”Ÿæˆé€šç”¨æå†™
    SWITCH sense_type:
        CASE "visual":
            RETURN f"{target.name}çš„é¢œè‰²/å½¢çŠ¶/çº¹ç†"
        CASE "tactile":
            RETURN f"è§¦æ„Ÿæå†™"
        CASE "auditory":
            RETURN f"å£°éŸ³æå†™"
        DEFAULT:
            RETURN f"{target.name}çš„ç‰¹å¾"
    END SWITCH
END FUNCTION

FUNCTION CONVERT_TO_SHOW_STYLE(telling_text):
    """å°†Tellå¼æ”¹ä¸ºShowå¼ï¼ˆç®€åŒ–å®ç°ï¼‰"""
    
    # ç§»é™¤"çœ‹åˆ°""æ„Ÿåˆ°"ç­‰Tellè¯
    telling_words = ["çœ‹åˆ°", "æ„Ÿåˆ°", "å¬åˆ°", "è§‰å¾—", "ä¼¼ä¹", "ä»¿ä½›"]
    
    result = telling_text
    FOR word IN telling_words:
        result = REPLACE(result, word, "")
    END FOR
    
    RETURN result.TRIM()
END FUNCTION
```

### 3.0.3 ååº”ç±»å‡½æ•°
```python
FUNCTION GENERATE_HESITATION_REACTION(protagonist, item, personality_type):
    """
    ç”ŸæˆçŠ¹è±«è¯•æ¢çš„ç”Ÿç†ååº”
    
    æ ¹æ®äººè®¾ç”Ÿæˆä¸åŒååº”ï¼š
    - è°¨æ…å‹ï¼šåé€€ã€è§‚å¯Ÿã€ç­‰å¾…
    - å†²åŠ¨å‹ï¼šç«‹å³è¡ŒåŠ¨ã€å¿½ç•¥é£é™©
    - ç†æ€§å‹ï¼šåˆ†æã€åˆ¤æ–­ã€è¯•æ¢
    """
    
    SWITCH personality_type:
        CASE "è°¨æ…":
            reactions = [
                f"{protagonist.name}åé€€äº†ä¸€æ­¥ã€‚",
                f"ä»–æ²¡æœ‰ç«‹åˆ»é è¿‘ã€‚",
                f"æ‰‹æ‚¬åœ¨åŠç©ºï¼Œåƒµäº†åæ¯ã€‚"
            ]
        
        CASE "å†²åŠ¨":
            reactions = [
                f"{protagonist.name}çœ¼ç›ä¸€äº®ã€‚",
                f"ä»–å‡ ä¹æ˜¯ä¸‹æ„è¯†åœ°ä¼¸å‡ºæ‰‹ã€‚",
                f"å¿ƒè·³åŠ å¿«ã€‚"
            ]
        
        CASE "ç†æ€§":
            reactions = [
                f"{protagonist.name}çš±èµ·çœ‰å¤´ã€‚",
                f"ä»–è¹²ä¸‹èº«ï¼Œç”¨æ ‘æè¯•æ¢æ€§åœ°ç¢°äº†ç¢°{item.name}ã€‚",
                f"è¿™ä¸åˆå¸¸ç†ã€‚"
            ]
        
        DEFAULT:
            reactions = [
                f"{protagonist.name}è¿Ÿç–‘äº†ç‰‡åˆ»ã€‚",
                f"å¿ƒè·³åŠ å¿«ã€‚"
            ]
    END SWITCH
    
    # éšæœºé€‰æ‹©1-2ä¸ªååº”ç»„åˆ
    count = RANDOM_CHOICE([1, 2])
    selected = RANDOM_SAMPLE(reactions, count)
    
    RETURN JOIN(selected, "\n\n")
END FUNCTION

FUNCTION GENERATE_PHYSIOLOGICAL_RESPONSE(emotion_type, intensity_level):
    """
    ç”Ÿæˆç”Ÿç†ååº”ï¼ˆå¤šå±‚æ¬¡ï¼‰
    
    å‚æ•°ï¼š
    - emotion_type: "fear"ææƒ§ / "excitement"å…´å¥‹ / "anger"æ„¤æ€’
    - intensity_level: "low"ä½ / "medium"ä¸­ / "high"é«˜
    """
    
    responses = []
    
    # æ ¹æ®æƒ…ç»ªç±»å‹é€‰æ‹©ååº”åº“
    IF emotion_type == "fear":
        layer1 = ["ç³å­”éª¤ç„¶æ”¶ç¼©", "å‘¼å¸ä¸€æ»"]
        layer2 = ["èƒƒéƒ¨åƒè¢«æ”¥ç´§", "åèƒŒå‘å‡‰"]
        layer3 = ["åŒè…¿å‘è½¯", "æ‰‹å¼€å§‹é¢¤æŠ–"]
    
    ELSE IF emotion_type == "excitement":
        layer1 = ["å¿ƒè·³åŠ é€Ÿ", "çœ¼ç›ä¸€äº®"]
        layer2 = ["è¡€æ¶²æ¶Œå‘å¤§è„‘", "å‘¼å¸æ€¥ä¿ƒ"]
        layer3 = ["æ‹³å¤´ä¸è‡ªè§‰æ¡ç´§", "å…¨èº«è‚Œè‚‰ç´§ç»·"]
    
    ELSE IF emotion_type == "anger":
        layer1 = ["å¤ªé˜³ç©´è·³åŠ¨", "è„¸æ¶¨å¾—é€šçº¢"]
        layer2 = ["èƒ¸å£åƒå‹ç€ä¸€å—çŸ³å¤´", "å‘¼å¸å˜å¾—æ²‰é‡"]
        layer3 = ["æŒ‡ç”²é™·è¿›æŒå¿ƒ", "ç‰™é½¿å’¬å¾—å’¯å’¯ä½œå“"]
    
    ELSE:
        # é»˜è®¤ï¼šä¸­æ€§ååº”
        RETURN "ä»–æ„£äº†ä¸€ä¸‹ã€‚"
    END IF
    
    # æ ¹æ®å¼ºåº¦é€‰æ‹©å±‚æ¬¡æ•°é‡
    SWITCH intensity_level:
        CASE "low":
            responses.APPEND(RANDOM_CHOICE(layer1))
        
        CASE "medium":
            responses.APPEND(RANDOM_CHOICE(layer1))
            responses.APPEND(RANDOM_CHOICE(layer2))
        
        CASE "high":
            responses.APPEND(RANDOM_CHOICE(layer1))
            responses.APPEND(RANDOM_CHOICE(layer2))
            responses.APPEND(RANDOM_CHOICE(layer3))
    END SWITCH
    
    RETURN JOIN(responses, "ã€‚\n\n") + "ã€‚"
END FUNCTION
```

### 3.0.4 å†³ç­–ç±»å‡½æ•°
```python
FUNCTION GENERATE_DECISION_MOMENT(protagonist, item, context, personality):
    """
    ç”Ÿæˆå†³ç­–æ—¶åˆ»
    
    å†³ç­–è¿‡ç¨‹ï¼š
    1. å†…å¿ƒæ–—äº‰ï¼ˆè´ªå¿µ vs ææƒ§ï¼‰
    2. æœ€ç»ˆè¡ŒåŠ¨
    """
    
    decision_text = ""
    
    # 1. å†…å¿ƒæ–—äº‰ï¼ˆç®€çŸ­ï¼Œä¸è¶…è¿‡2å¥ï¼‰
    IF personality IN ["è°¨æ…", "ç†æ€§"]:
        conflict = f"ç¢°è¿˜æ˜¯ä¸ç¢°ï¼Ÿ\n\n"
    ELSE IF personality == "å†²åŠ¨":
        conflict = f"ç®¡ä¸äº†é‚£ä¹ˆå¤šäº†ã€‚\n\n"
    ELSE:
        conflict = ""
    END IF
    
    decision_text += conflict
    
    # 2. æœ€ç»ˆè¡ŒåŠ¨
    action = f"{protagonist.name}"
    
    IF personality == "è°¨æ…":
        action += "çœ‹äº†çœ¼å››å‘¨ï¼Œç¡®è®¤æ— äººï¼Œæ‰å°å¿ƒç¿¼ç¿¼åœ°ä¼¸å‡ºæ‰‹ã€‚"
    ELSE IF personality == "å†²åŠ¨":
        action += "ç›´æ¥æŠ“èµ·{item.name}ã€‚"
    ELSE:
        action += "ä¼¸æ‰‹æ‹¿èµ·{item.name}ã€‚"
    END IF
    
    decision_text += action
    
    RETURN decision_text
END FUNCTION
```

### 3.0.5 å¯¹è¯ç±»å‡½æ•°
```python
FUNCTION GENERATE_FUNCTIONAL_DIALOGUE(speaker, intent, context, previous_line=NULL):
    """
    ç”ŸæˆåŠŸèƒ½æ€§å¯¹è¯ï¼ˆæ¨è¿›å‰§æƒ…æˆ–æ­ç¤ºè§’è‰²ï¼‰
    
    intentç±»å‹ï¼š
    - "reveal_info": æ­ç¤ºæ–°ä¿¡æ¯
    - "escalate_conflict": å‡çº§å†²çª
    - "build_relationship": å»ºç«‹å…³ç³»
    - "deflect": è½¬ç§»è¯é¢˜
    """
    
    personality = speaker.GET("personality", "ä¸­æ€§")
    speech_style = speaker.GET("speech_style", [])
    
    dialogue = ""
    
    SWITCH intent:
        CASE "reveal_info":
            # ç”Ÿæˆæ­ç¤ºä¿¡æ¯çš„å¯¹è¯
            info = context.GET("info_to_reveal", "æŸä¸ªç§˜å¯†")
			IF personality == "ç›´ç‡":
            dialogue = f"æˆ‘å‘Šè¯‰ä½ ï¼Œ{info}ã€‚"
        ELSE IF personality == "ç‹¡çŒ¾":
            dialogue = f"ä½ æƒ³çŸ¥é“{info}ï¼Ÿå…ˆå›ç­”æˆ‘ä¸€ä¸ªé—®é¢˜ã€‚"
        ELSE:
            dialogue = f"å…³äº{info}ï¼Œæˆ‘çŸ¥é“ä¸€äº›ã€‚"
        END IF
    
    CASE "escalate_conflict":
        # ç”Ÿæˆæ¿€åŒ–å†²çªçš„å¯¹è¯
        IF previous_line:
            IF personality == "æš´èº":
                dialogue = f"ä½ è¯´ä»€ä¹ˆï¼Ÿï¼"
            ELSE IF personality == "å†·é™":
                dialogue = f"è¿™å°±æ˜¯ä½ çš„ç­”æ¡ˆï¼Ÿ"
            ELSE:
                dialogue = f"ä¸å¯¹ã€‚"
            END IF
        ELSE:
            dialogue = f"æˆ‘ä¸åŒæ„ã€‚"
        END IF
    
    CASE "build_relationship":
        # ç”Ÿæˆå»ºç«‹å…³ç³»çš„å¯¹è¯
        relationship = context.GET("relationship_temp", 50)
        
        IF relationship < 30:
            dialogue = f"ä½ æ˜¯è°ï¼Ÿ"
        ELSE IF relationship < 60:
            dialogue = f"éœ€è¦å¸®å¿™å—ï¼Ÿ"
        ELSE:
            dialogue = f"åˆè§é¢äº†ã€‚"
        END IF
    
    CASE "deflect":
        # è½¬ç§»è¯é¢˜
        dialogue = f"å…ˆä¸è¯´è¿™ä¸ªï¼Œ{RANDOM_CHOICE(['ä½ åƒäº†å—', 'å¤©æ°”ä¸é”™', 'æ—¶é—´ä¸æ—©äº†'])}ã€‚"

	END SWITCH

	# åº”ç”¨è¯´è¯é£æ ¼
	dialogue = APPLY_SPEECH_STYLE(dialogue, speech_style)

	RETURN dialogue
	END FUNCTION
	FUNCTION APPLY_SPEECH_STYLE(dialogue, speech_style):
	"""åº”ç”¨è¯´è¯é£æ ¼"""

	IF "ç®€çŸ­" IN speech_style:
		# åˆ é™¤å†—ä½™è¯
		dialogue = REPLACE(dialogue, "é‚£ä¸ª", "")
		dialogue = REPLACE(dialogue, "è¿™ä¸ª", "")
	END IF

	IF "æ–‡é›…" IN speech_style:
		# æ·»åŠ æ–‡è¨€è™šè¯
		dialogue = REPLACE(dialogue, "å—ï¼Ÿ", "å¦ï¼Ÿ")
	END IF

	IF "ç²—é²" IN speech_style:
		# æ·»åŠ è¯­æ°”è¯
		IF NOT dialogue.ENDSWITH("ï¼"):
			dialogue += "ï¼"
		END IF
	END IF

	RETURN dialogue
END FUNCTION
```

### 3.1 å‘ç°åœºæ™¯æ¨¡å¼

```python

FUNCTION WRITE_DISCOVERY_SCENE(item, context, constraints):
    """
    å‘ç°åœºæ™¯æ ‡å‡†æ¨¡å¼ï¼ˆæ”¹è¿›ç‰ˆï¼šè°ƒç”¨åŸºç¡€å‡½æ•°ï¼‰
    
    ç»“æ„ï¼šè§¦å‘ â†’ è§‚å¯Ÿ â†’ çŠ¹è±« â†’ å†³ç­– â†’ åæœæš—ç¤º
    """
    
    scene_text = ""
    protagonist = context.protagonist
    
    # é˜¶æ®µ1ï¼šè§¦å‘äº‹ä»¶ï¼ˆè°ƒç”¨åŸºç¡€å‡½æ•°ï¼‰
    trigger = GENERATE_DISCOVERY_TRIGGER(
        item=item,
        protagonist=protagonist,
        environment=context.environment,
        style="minimal"  # ç®€çŸ­ï¼Œå¼•å‘å¥½å¥‡
    )
    scene_text += trigger + "\n\n"
    
    # é˜¶æ®µ2ï¼šè§‚å¯Ÿç»†èŠ‚ï¼ˆè°ƒç”¨åŸºç¡€å‡½æ•°ï¼‰
    observation = GENERATE_OBSERVATION_SEQUENCE(
        target=item,
        sensory_focus=["visual", "tactile"],  # è§†è§‰+è§¦è§‰
        detail_level="medium",
        avoid_telling=TRUE
    )
    scene_text += observation + "\n\n"
    
    # é˜¶æ®µ3ï¼šç”Ÿç†ååº”/çŠ¹è±«ï¼ˆè°ƒç”¨åŸºç¡€å‡½æ•°ï¼‰
    personality = protagonist.GET("personality", "è°¨æ…")
    hesitation = GENERATE_HESITATION_REACTION(protagonist, item, personality)
    scene_text += hesitation + "\n\n"
    
    # é˜¶æ®µ4ï¼šå†³ç­–ä¸è¡ŒåŠ¨ï¼ˆè°ƒç”¨åŸºç¡€å‡½æ•°ï¼‰
    decision = GENERATE_DECISION_MOMENT(protagonist, item, context, personality)
    scene_text += decision + "\n\n"
    
    # é˜¶æ®µ5ï¼šåæœæš—ç¤ºï¼ˆåŸ‹é’©å­ï¼‰
    consequence_hint = PLANT_CONSEQUENCE_SEED(item, context)
    scene_text += consequence_hint
    
    RETURN scene_text
END FUNCTION

FUNCTION PLANT_CONSEQUENCE_SEED(item, context):
    """åŸ‹ä¸‹åæœçš„ç§å­ï¼ˆä¼ç¬”ï¼‰"""
    
    # æ ¹æ®ç‰©å“ç±»å‹é€‰æ‹©ä¼ç¬”æ–¹å¼
    IF item.GET("is_dangerous", FALSE):
        hints = [
            f"{item.name}çš„æ¸©åº¦ï¼Œè¶Šæ¥è¶Šçƒ«ã€‚",
            f"æŸç§ä¸å®‰åœ¨å¿ƒåº•è”“å»¶ã€‚",
            f"è¿™ä¸œè¥¿ï¼Œä¸å¤ªå¯¹åŠ²ã€‚"
        ]
    ELSE IF item.GET("is_valuable", TRUE):
        hints = [
            f"{item.name}é™é™èººåœ¨æ€€é‡Œã€‚",
            f"è¿™æˆ–è®¸æ˜¯ä¸ªæœºä¼šã€‚",
            f"å‘½è¿çš„é½¿è½®ï¼Œå¼€å§‹è½¬åŠ¨ã€‚"
        ]
    ELSE:
        hints = [
            f"{item.name}è¿˜åœ¨é‚£é‡Œã€‚",
            f"ä¸€åˆ‡å¦‚å¸¸ã€‚"
        ]
    END IF
    
    RETURN RANDOM_CHOICE(hints)
END FUNCTION

FUNCTION GENERATE_SENSORY_DETAILS(item, context):
    """ç”Ÿæˆæ„Ÿå®˜ç»†èŠ‚ï¼ˆå‚è€ƒÂ§13æ„Ÿå®˜ç´ æåº“ï¼‰"""
    
    # ä»èƒ¶å›Šæå–æ„Ÿå®˜ç´ æ
    IF item.name IN context.sensors:
        materials = context.sensors[item.name]
        
        details = []
        IF "visual" IN materials:
            details.APPEND(RANDOM_CHOICE(materials.visual))
        END IF
        IF "tactile" IN materials:
            details.APPEND(RANDOM_CHOICE(materials.tactile))
        END IF
        
        RETURN JOIN(details, "ï¼Œ") + "ã€‚"
    END IF
    
    # é»˜è®¤ç”Ÿæˆ
    RETURN f"{item.name}é™é™èººåœ¨é‚£é‡Œã€‚"
END FUNCTION

FUNCTION GENERATE_HESITATION_REACTION(protagonist, item):
    """ç”ŸæˆçŠ¹è±«æ—¶çš„ç”Ÿç†ååº”"""
    
    # æ ¹æ®è§’è‰²æ€§æ ¼é€‰æ‹©ååº”ç±»å‹
    IF protagonist.personality IN ["è°¨æ…", "å¤šç–‘"]:
        reactions = [
            f"{protagonist.name}çš„æ‰‹æ‚¬åœ¨åŠç©ºï¼Œåƒµäº†è¶³è¶³åæ¯ã€‚",
            f"{protagonist.name}ç›¯ç€{item.name}ï¼Œä¸æ•¢é è¿‘ã€‚",
            f"{protagonist.name}åé€€ä¸€æ­¥ï¼Œæ‰‹å¿ƒå†’æ±—ã€‚"
        ]
    ELSE IF protagonist.personality IN ["å†²åŠ¨", "å¥½å¥‡"]:
        reactions = [
            f"{protagonist.name}çœ¼ç›ä¸€äº®ã€‚",
            f"{protagonist.name}å¿ä¸ä½ä¼¸æ‰‹ã€‚",
            f"{protagonist.name}å‘¼å¸æ€¥ä¿ƒèµ·æ¥ã€‚"
        ]
    ELSE:
        reactions = [
            f"{protagonist.name}è¿Ÿç–‘äº†ç‰‡åˆ»ã€‚",
            f"{protagonist.name}å¿ƒè·³åŠ å¿«ã€‚"
        ]
    END IF
    
    RETURN RANDOM_CHOICE(reactions)
END FUNCTION
```

### 3.2 å¯¹è¯åœºæ™¯æ¨¡å¼

```python
FUNCTION WRITE_DIALOGUE_SCENE(characters, topic, context, constraints):
    """
    å¯¹è¯åœºæ™¯æ ‡å‡†æ¨¡å¼
    
    ç»“æ„ï¼šå¼€åœº â†’ è¯•æ¢ â†’ ä¿¡æ¯äº¤æ¢/å†²çª â†’ ç»“è®º
    
    æ ¸å¿ƒï¼šæ¯å¥å¯¹è¯éƒ½è¦æ¨è¿›å‰§æƒ…æˆ–æ­ç¤ºè§’è‰²
    """
    
    scene_text = ""
    dialogue_count = 0
    max_exchanges = ESTIMATE_DIALOGUE_EXCHANGES(constraints.budget)
    
    # é˜¶æ®µ1ï¼šå¼€åœºï¼ˆå»ºç«‹åœºæ™¯å’Œæ°›å›´ï¼‰
    opening = WRITE_DIALOGUE_OPENING(characters, context)
    scene_text += opening + "\n\n"
    
    # é˜¶æ®µ2ï¼šå¯¹è¯ä¸»ä½“
    WHILE dialogue_count < max_exchanges:
        # 2.1 è§’è‰²Aè¯´è¯
        speaker_a = characters[0]
        line_a = GENERATE_DIALOGUE_LINE(
            speaker_a,
            topic,
            context,
            intent="ADVANCE_GOAL"  # æ¨è¿›ç›®æ ‡
        )
        
        scene_text += f""{line_a}"\n\n"
        dialogue_count += 1
        
        # 2.2 è§’è‰²Bååº”
        speaker_b = characters[1]
        
        # 30%æ¦‚ç‡ä¸æ¥èŒ¬ï¼ˆæ‹ŸäººåŒ–ï¼‰
        IF RANDOM() < 0.3:
            non_response = GENERATE_NON_RESPONSE_ACTION(speaker_b, context)
            scene_text += non_response + "\n\n"
        ELSE:
            line_b = GENERATE_DIALOGUE_LINE(
                speaker_b,
                topic,
                context,
                intent="RESPOND_OR_DEFLECT",
                previous_line=line_a
            )
            scene_text += f""{line_b}"\n\n"
            dialogue_count += 1
        END IF
        
        # 2.3 æ£€æŸ¥æ˜¯å¦è¾¾æˆåœºæ™¯ç›®æ ‡
        IF SCENE_GOAL_REACHED(scene_text, context.literary_goal):
            BREAK
        END IF
    END WHILE
    
    # é˜¶æ®µ3ï¼šç»“å°¾ï¼ˆä¸è¦æ€»ç»“ï¼Œç”¨åŠ¨ä½œæˆ–æœªç«Ÿä¹‹æ„ï¼‰
    ending = WRITE_DIALOGUE_ENDING_WITHOUT_SUMMARY(characters, context)
    scene_text += ending
    
    RETURN scene_text
END FUNCTION

FUNCTION GENERATE_DIALOGUE_LINE(speaker, topic, context, intent, previous_line=NULL):
    """
    ç”Ÿæˆå¯¹è¯è¡Œ
    
    intentå¯èƒ½å€¼ï¼š
    - ADVANCE_GOAL: æ¨è¿›åœºæ™¯ç›®æ ‡
    - RESPOND_OR_DEFLECT: å›åº”æˆ–è½¬ç§»è¯é¢˜
    - REVEAL_INFO: æ­ç¤ºä¿¡æ¯
    - ESCALATE_CONFLICT: å‡çº§å†²çª
    """
    
    # æ ¹æ®è§’è‰²æ€§æ ¼å’Œæ„å›¾ç”Ÿæˆå¯¹è¯
    personality = speaker.GET("personality", "ä¸­æ€§")
    speech_style = speaker.GET("speech_style", [])
    
    # ç¤ºä¾‹ç”Ÿæˆé€»è¾‘ï¼ˆå®é™…åº”æ›´å¤æ‚ï¼‰
    IF intent == "ADVANCE_GOAL":
        # æ¨è¿›ç›®æ ‡ï¼šç›´æ¥é—®å…³é”®é—®é¢˜
        line = GENERATE_GOAL_ADVANCING_LINE(speaker, topic, context)
    ELSE IF intent == "RESPOND_OR_DEFLECT":
        # å›åº”ï¼šæ ¹æ®å…³ç³»æ¸©åº¦å†³å®šå¦è¯šåº¦
        relationship = GET_RELATIONSHIP(speaker, previous_line.speaker, context)
        IF relationship.temperature < 30:
            line = GENERATE_DEFLECTING_LINE(speaker, previous_line)
        ELSE:
            line = GENERATE_HONEST_RESPONSE(speaker, previous_line)
        END IF
    END IF
    
    # åº”ç”¨è¯´è¯é£æ ¼
    line = APPLY_SPEECH_STYLE(line, speech_style)
    
    RETURN line
END FUNCTION
```

### 3.3 å†²çªåœºæ™¯æ¨¡å¼

```python
FUNCTION WRITE_CONFLICT_SCENE(parties, conflict_type, context, constraints):
    """
    å†²çªåœºæ™¯æ ‡å‡†æ¨¡å¼
    
    ç»“æ„ï¼šå¼•çˆ†ç‚¹ â†’ ç«‹åœºæ˜ç¡® â†’ äº¤é”‹å‡çº§ â†’ æš‚æ—¶ç»“æœ
    
    æ ¸å¿ƒï¼šå¿«èŠ‚å¥ï¼Œä¸æ‹–æ²“ï¼Œæ¯ä¸ªå›åˆéƒ½å‡çº§
    """
    
    scene_text = ""
    intensity = 30  # å†²çªå¼ºåº¦ï¼ˆåˆå§‹å€¼ï¼‰
    
    # é˜¶æ®µ1ï¼šå¼•çˆ†ç‚¹ï¼ˆç›´æ¥è¿›å…¥å†²çªï¼Œä¸é“ºå«ï¼‰
    trigger = WRITE_CONFLICT_TRIGGER(parties, conflict_type, context)
    scene_text += trigger + "\n\n"
    
    # é˜¶æ®µ2ï¼šäº¤é”‹ï¼ˆ3-5ä¸ªå›åˆï¼Œé€æ­¥å‡çº§ï¼‰
    round_count = 0
    max_rounds = 5
    
    WHILE round_count < max_rounds AND intensity < 90:
        # 2.1 ä¸€æ–¹å‡ºæ‹›
        attacker = parties[round_count % LENGTH(parties)]
        move = GENERATE_CONFLICT_MOVE(attacker, intensity, context)
        scene_text += move + "\n\n"
        
        # 2.2 å¦ä¸€æ–¹åå‡»
        defender = parties[(round_count + 1) % LENGTH(parties)]
        counter = GENERATE_CONFLICT_COUNTER(defender, move, intensity, context)
        scene_text += counter + "\n\n"
        
        # 2.3 å‡çº§å†²çªå¼ºåº¦
        intensity += 15
        round_count += 1
        
        # 2.4 æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å³°å€¼
        IF intensity >= 85:
            BREAK
        END IF
    END WHILE
    
    # é˜¶æ®µ3ï¼šæš‚æ—¶ç»“æœï¼ˆä¸è¦å®Œå…¨è§£å†³ï¼Œç•™æ‚¬å¿µï¼‰
    temporary_result = WRITE_TEMPORARY_RESOLUTION(parties, intensity, context)
    scene_text += temporary_result
    
    RETURN scene_text
END FUNCTION
```

### 3.4 å±æœºåœºæ™¯æ¨¡å¼

```python
FUNCTION WRITE_CRISIS_SCENE(danger, protagonist, context, constraints):
    """
    å±æœºåœºæ™¯æ ‡å‡†æ¨¡å¼
    
    ç»“æ„ï¼šå±æœºé™ä¸´ â†’ ç”Ÿç†ååº” â†’ æœ¬èƒ½åº”å¯¹ â†’ æš‚æ—¶å®‰å…¨
    
    æ ¸å¿ƒï¼šç´§å¼ æ„Ÿã€ä»£å…¥æ„Ÿã€å¿«èŠ‚å¥
    """
    
    scene_text = ""
    
    # é˜¶æ®µ1ï¼šå±æœºé™ä¸´ï¼ˆå¿«é€Ÿåˆ‡å…¥ï¼Œä¸è§£é‡Šï¼‰
    crisis_start = WRITE_CRISIS_ONSET(danger, context)
    scene_text += crisis_start + "\n\n"
    
    # é˜¶æ®µ2ï¼šç”Ÿç†ååº”ï¼ˆè¯¦å†™èº«ä½“ååº”ï¼Œä¸å†™å†…å¿ƒæˆï¼‰
    physiological = GENERATE_CRISIS_PHYSIOLOGY(protagonist, danger)
    scene_text += physiological + "\n\n"
    
    # é˜¶æ®µ3ï¼šæœ¬èƒ½åº”å¯¹ï¼ˆçŸ­å¥ï¼Œå¿«èŠ‚å¥ï¼‰
    action_sequence = WRITE_CRISIS_RESPONSE(protagonist, danger, context)
    scene_text += action_sequence + "\n\n"
    
    # é˜¶æ®µ4ï¼šæš‚æ—¶å®‰å…¨ï¼ˆä¸è¦å®Œå…¨è§£é™¤å±æœºï¼‰
    temporary_safety = WRITE_TEMPORARY_SAFETY(protagonist, danger, context)
    scene_text += temporary_safety
    
    RETURN scene_text
END FUNCTION

FUNCTION GENERATE_CRISIS_PHYSIOLOGY(protagonist, danger):
    """ç”Ÿæˆå±æœºæ—¶çš„ç”Ÿç†ååº”ï¼ˆå¤šå±‚æ¬¡ï¼‰"""
    
    reactions = [
        # å±‚æ¬¡1ï¼šç¬é—´ååº”
        f"{protagonist.name}çš„ç³å­”éª¤ç„¶æ”¶ç¼©ã€‚",
        
        # å±‚æ¬¡2ï¼šå†…è„ååº”
        "èƒƒéƒ¨åƒè¢«ä¸€åªå†°å†·çš„æ‰‹æ”¥ç´§ã€‚",
        
        # å±‚æ¬¡3ï¼šè‚Œè‚‰ååº”
        "åŒè…¿å‘è½¯ï¼Œå‡ ä¹ç«™ä¸ç¨³ã€‚",
        
        # å±‚æ¬¡4ï¼šæ„Ÿå®˜ååº”
        "è€³é¸£å£°å°–é”ï¼Œå‘¨å›´çš„å£°éŸ³å˜å¾—æ¨¡ç³Šã€‚"
    ]
    
    # æ ¹æ®å±æœºå¼ºåº¦é€‰æ‹©ååº”æ•°é‡
    IF danger.intensity > 80:
        RETURN JOIN(reactions, "") # å…¨éƒ¨ååº”
    ELSE IF danger.intensity > 50:
        RETURN JOIN(reactions[:3], "")  # å‰3ä¸ª
    ELSE:
        RETURN JOIN(reactions[:2], "")  # å‰2ä¸ª
    END IF
END FUNCTION
```

---

## Â§4 å†™ä½œæ‰§è¡Œæµç¨‹ | é›†æˆé¢„è¯Šæ–­

### 4.1 ä¸»æ‰§è¡Œæµç¨‹

```python
FUNCTION MAIN_EXECUTION_V4(CAPSULE):
    """
    ä¸»æ‰§è¡Œæµç¨‹ v4.0
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. é¢„è¯Šæ–­æœºåˆ¶
    2. åœºæ™¯ç±»å‹é©±åŠ¨
    3. æ–‡å­¦æ€§ä¼˜å…ˆ
    """
    
    # STEP 1: è§£æèƒ¶å›Š
    parsed_data = PARSE_CAPSULE(CAPSULE)
    
    # STEP 2: ç« èŠ‚è§„åˆ’
    plan = PLAN_CHAPTER(parsed_data)
    
    # STEP 3: é¢„è¯Šæ–­ï¼ˆæ–°å¢ï¼‰
    pre_diagnosis = PRE_DIAGNOSE_PLAN(plan, parsed_data)
    
    IF pre_diagnosis.has_critical_risks:
        PRINT "[WARNING] é¢„è¯Šæ–­å‘ç°é£é™©ï¼š"
        FOR risk IN pre_diagnosis.risks:
            PRINT f"  - {risk.description}"
            PRINT f"    å»ºè®®: {risk.suggestion}"
        END FOR
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        # ï¼ˆåœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥ç­‰å¾…äººç±»ç¡®è®¤æˆ–è‡ªåŠ¨è°ƒæ•´ï¼‰
    END IF
    
    # STEP 4: åœºæ™¯å†™ä½œ
    chapter_content = ""
    monitors = INIT_MONITORS()
    
    FOR scene_plan IN plan.scenes:
        PRINT f"[SCENE {scene_plan.scene_idx}] ç±»å‹:{scene_plan.type} | ç›®æ ‡:{scene_plan.literary_goal}"
        
        # 4.1 é€‰æ‹©å†™ä½œæ¨¡å¼
        scene_text = WRITE_SCENE_BY_TYPE(
            scene_plan,
            parsed_data,
            chapter_content,  # å‰æ–‡ä¸Šä¸‹æ–‡
            monitors
        )
        
        # 4.2 åœºæ™¯çº§è´¨é‡æ£€æŸ¥
        scene_check = CHECK_SCENE_QUALITY(scene_text, scene_plan, parsed_data)
		
		        
        IF scene_check.severity == "CRITICAL":
            # ç«‹å³é‡å†™åœºæ™¯
            scene_text = REWRITE_SCENE_WITH_GUIDANCE(scene_plan, scene_check, parsed_data)
        END IF
        
		        
        # ========== æ–°å¢ï¼š4.3 ç•ªèŒ„é£æ ¼æ£€æŸ¥ ==========
        tomato_check = CHECK_TOMATO_STYLE(scene_text, scene_plan, monitors)
        
        IF tomato_check.severity == "CRITICAL":
            PRINT f"[TOMATO] åœºæ™¯{scene_plan.scene_idx}ç•ªèŒ„é£æ ¼é—®é¢˜ï¼š{tomato_check.issue}"
            # é‡å†™åœºæ™¯ï¼Œæ³¨å…¥ç•ªèŒ„å…ƒç´ 
            scene_text = REWRITE_WITH_TOMATO_BOOST(scene_plan, tomato_check, parsed_data)
        END IF
        
        # 4.4 æ£€æŸ¥çˆ½ç‚¹ï¼ˆå¦‚æœè®¡åˆ’ä¸­æœ‰ï¼‰
        IF scene_plan.scene_idx IN plan.cool_point_plan:
            cool_type = plan.cool_point_plan[scene_plan.scene_idx]
            
            IF NOT DETECT_COOL_POINT_IN_SCENE(scene_text, cool_type):
                PRINT f"[COOL] åœºæ™¯{scene_plan.scene_idx}ç¼ºå°‘çˆ½ç‚¹ï¼Œè¡¥å……ä¸­..."
                scene_text = INJECT_COOL_POINT(scene_text, cool_type, parsed_data)
            END IF
        END IF
        

        chapter_content += scene_text
        UPDATE_MONITORS(monitors, scene_text, scene_plan)
    END FOR
    
    # STEP 5: å…¨å±€æ¶¦è‰²ï¼ˆè½»é‡åŒ–ï¼‰
    chapter_content = LIGHT_POLISH(chapter_content, parsed_data)
    
    # STEP 6: æ–‡å­¦æ€§è¯Šæ–­
    diagnosis = DIAGNOSE_LITERARY_QUALITY(chapter_content, parsed_data, plan)
    
    # STEP 7: æ™ºèƒ½ä¿®å¤æˆ–é‡å†™
    IF diagnosis.needs_rewrite:
        RETURN INTELLIGENT_REWRITE(CAPSULE, plan, diagnosis)
    ELSE IF diagnosis.needs_fix:
        chapter_content = APPLY_FIXES(chapter_content, diagnosis.fixes, parsed_data)
    END IF
    
    # STEP 8: æå–Factå¹¶äº¤ä»˜
    new_facts = EXTRACT_FACTS(chapter_content, parsed_data)
    
    RETURN DELIVER_OUTPUT_V4(chapter_content, new_facts, diagnosis, plan)
END FUNCTION
```

### 4.2 é¢„è¯Šæ–­æœºåˆ¶

```python
FUNCTION PRE_DIAGNOSE_PLAN(plan, parsed_data):
    """
    å†™ä½œå‰çš„é¢„è¯Šæ–­
    
    ç›®æ ‡ï¼šåœ¨å†™ä½œå‰å‘ç°æ½œåœ¨é—®é¢˜ï¼Œè€Œéå†™å®Œäº†å†è¿”å·¥
    """
    
    pre_diagnosis = {
        "has_critical_risks": FALSE,
        "risks": [],
        "suggestions": []
    }
    
    # é£é™©1ï¼šå¯¹è¯å æ¯”é¢„ä¼°
    estimated_dialogue_ratio = ESTIMATE_DIALOGUE_RATIO_FROM_PLAN(plan)
    
    IF estimated_dialogue_ratio < 0.25:
        pre_diagnosis.risks.APPEND({
            "type": "LOW_DIALOGUE",
            "description": f"é¢„è®¡å¯¹è¯å æ¯”{estimated_dialogue_ratio*100:.0f}%ï¼Œå¯èƒ½è¿‡ä½",
            "suggestion": "å»ºè®®åœ¨åœºæ™¯2æˆ–åœºæ™¯3å¢åŠ åŒäººå¯¹è¯åœºæ™¯",
            "severity": "WARNING"
        })
    END IF
    
    # é£é™©2ï¼šåœºæ™¯æ•°é‡ä¸å­—æ•°é¢„ç®—
    total_budget = plan.total_budget
    scene_count = LENGTH(plan.scenes)
    avg_scene_words = total_budget / scene_count
    
    IF avg_scene_words < 300 OR avg_scene_words > 1200:
        pre_diagnosis.has_critical_risks = TRUE
        pre_diagnosis.risks.APPEND({
            "type": "SCENE_BUDGET_MISMATCH",
            "description": f"åœºæ™¯æ•°{scene_count}ä¸ªï¼Œå¹³å‡{avg_scene_words:.0f}å­—/åœºæ™¯ï¼Œè¶…å‡ºåˆç†èŒƒå›´",
            "suggestion": f"å»ºè®®è°ƒæ•´ä¸º{ROUND(total_budget/750)}ä¸ªåœºæ™¯",
            "severity": "CRITICAL"
        })
    END IF
    
    # é£é™©3ï¼šæ ¸å¿ƒä»»åŠ¡åˆ†é…
    core_mission = parsed_data.goals.GET("core_mission", "")
    IF core_mission:
        mission_scenes = COUNT_SCENES_FOR_MISSION(plan, core_mission)
        IF mission_scenes == 0:
            pre_diagnosis.has_critical_risks = TRUE
            pre_diagnosis.risks.APPEND({
                "type": "MISSION_NOT_PLANNED",
                "description": "æ ¸å¿ƒä»»åŠ¡æœªåˆ†é…åˆ°ä»»ä½•åœºæ™¯",
                "suggestion": "è¯·åœ¨åœºæ™¯è®¡åˆ’ä¸­æ˜ç¡®å“ªä¸ªåœºæ™¯å®Œæˆæ ¸å¿ƒä»»åŠ¡",
                "severity": "CRITICAL"
            })
        END IF
    END IF
    
    # é£é™©4ï¼šåœºæ™¯ç±»å‹å•ä¸€
    scene_types = MAP(plan.scenes, lambda s: s.type)
    unique_types = UNIQUE(scene_types)
    
    IF LENGTH(unique_types) == 1:
        pre_diagnosis.risks.APPEND({
            "type": "TYPE_MONOTONY",
            "description": f"æ‰€æœ‰åœºæ™¯éƒ½æ˜¯"{unique_types[0]}"ç±»å‹ï¼Œå¯èƒ½å•è°ƒ",
            "suggestion": "è€ƒè™‘æ··åˆä¸åŒåœºæ™¯ç±»å‹ä»¥å¢åŠ èŠ‚å¥å˜åŒ–",
            "severity": "WARNING"
        })
    END IF
    
    RETURN pre_diagnosis
END FUNCTION

FUNCTION ESTIMATE_DIALOGUE_RATIO_FROM_PLAN(plan):
    """ä»åœºæ™¯è®¡åˆ’é¢„ä¼°å¯¹è¯å æ¯”"""
    
    total_dialogue_weight = 0
    total_weight = 0
    
    FOR scene_plan IN plan.scenes:
        scene_type = scene_plan.type
        constraints = SCENE_TYPES[scene_type]
        
        # å–å¯¹è¯èŒƒå›´çš„ä¸­ä½æ•°
        dialogue_mid = (constraints.å¯¹è¯èŒƒå›´[0] + constraints.å¯¹è¯èŒƒå›´[1]) / 2
        
        total_dialogue_weight += scene_plan.budget * dialogue_mid
        total_weight += scene_plan.budget
    END FOR
    
    IF total_weight == 0:
        RETURN 0
    END IF
    
    RETURN total_dialogue_weight / total_weight
END FUNCTION
```

### 4.3 åœºæ™¯å†™ä½œè°ƒåº¦

```python
FUNCTION WRITE_SCENE_BY_TYPE(scene_plan, parsed_data, previous_content, monitors):
    """
    æ ¹æ®åœºæ™¯ç±»å‹é€‰æ‹©å†™ä½œæ¨¡å¼
    """
    
    scene_type = scene_plan.type
    
    SWITCH scene_type:
        CASE "ç‹¬å¤„æ¢ç´¢":
            # æ£€æŸ¥æ˜¯å¦æœ‰å‘ç°ç‰©å“
            IF "discovery_item" IN scene_plan.must_include:
                item = scene_plan.must_include.discovery_item
                RETURN WRITE_DISCOVERY_SCENE(item, parsed_data, scene_plan.constraints)
            ELSE:
                RETURN WRITE_SOLO_EXPLORATION(scene_plan, parsed_data)
            END IF
        
        CASE "åŒäººå¯¹è¯":
            characters = EXTRACT_CHARACTERS_FROM_PLAN(scene_plan, parsed_data)
            topic = scene_plan.literary_goal
            RETURN WRITE_DIALOGUE_SCENE(characters, topic, parsed_data, scene_plan.constraints)
        
        CASE "ç¾¤æˆå†²çª":
            parties = EXTRACT_PARTIES_FROM_PLAN(scene_plan, parsed_data)
            conflict_type = scene_plan.GET("conflict_type", "åˆ©ç›Šå†²çª")
            RETURN WRITE_CONFLICT_SCENE(parties, conflict_type, parsed_data, scene_plan.constraints)
        
        CASE "å±æœºååº”":
            danger = scene_plan.must_include.GET("danger", {})
            protagonist = parsed_data.characters.protagonist
            RETURN WRITE_CRISIS_SCENE(danger, protagonist, parsed_data, scene_plan.constraints)
        
        CASE "æƒ…æ„Ÿè½¬æŠ˜":
            RETURN WRITE_EMOTION_TURN_SCENE(scene_plan, parsed_data)
        
        DEFAULT:
            # é»˜è®¤ï¼šä½¿ç”¨é€šç”¨åœºæ™¯å†™ä½œ
            RETURN WRITE_GENERIC_SCENE(scene_plan, parsed_data)
    END SWITCH
END FUNCTION
```

### 4.4 ğŸ… ç•ªèŒ„é£æ ¼è´¨é‡ç³»ç»Ÿï¼ˆç½‘æ–‡æ ¸å¿ƒç‰¹è‰²ï¼‰(é‡ç‚¹)ğŸ…

> **è®¾è®¡ç›®æ ‡**ï¼šç¡®ä¿ç« èŠ‚ç¬¦åˆç•ªèŒ„å°è¯´çš„æ ¸å¿ƒç‰¹è‰²â€”â€”çˆ½ç‚¹å¯†é›†ã€é’©å­é¢‘ç¹ã€èŠ‚å¥ç´§å‡‘ã€ä¿¡æ¯é‡å¤§ã€‚


### 4.4.1 çˆ½ç‚¹æ£€æµ‹ä¸æ³¨å…¥

```python
FUNCTION CHECK_TOMATO_STYLE(scene_text, scene_plan, monitors):
    """
    æ£€æŸ¥åœºæ™¯æ˜¯å¦ç¬¦åˆç•ªèŒ„é£æ ¼
    
    æ£€æŸ¥é¡¹ï¼š
    1. é’©å­é¢‘ç‡ï¼ˆ600å­—å†…å¿…é¡»æœ‰æ–°ä¿¡æ¯/å†²çªï¼‰
    2. ä¿¡æ¯å¯†åº¦ï¼ˆæ¯100å­—â‰¥1ä¸ªä¿¡æ¯ç‚¹ï¼‰
    3. æ®µè½é•¿åº¦ï¼ˆå•æ®µâ‰¤150å­—ï¼‰
    4. èŠ‚å¥æ§åˆ¶ï¼ˆæ— èŠåº¦æ£€æµ‹ï¼‰
    """
    
    check_result = {
        "severity": "OK",
        "issue": "",
        "fix_suggestions": []
    }
    
    tomato_constraints = SCENE_TYPES[scene_plan.type].tomato_constraints
    
    # æ£€æŸ¥1ï¼šé’©å­é—´éš”
    last_hook_position = 0
    current_position = 0
    max_gap = 0
    
    FOR para IN SPLIT_PARAGRAPHS(scene_text):
        current_position += LENGTH(para)
        
		
		    
    # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
    context = {
        "previous_dialogues": monitors.GET("recent_dialogues", []),
        "last_emotion": monitors.GET("last_emotion", 50),
        "known_characters": monitors.GET("known_characters", [])
    }
    
		IF HAS_HOOK(para, context):  # ä¼ å…¥ä¸Šä¸‹æ–‡
            gap = current_position - last_hook_position
            max_gap = MAX(max_gap, gap)
            last_hook_position = current_position
        END IF
    END FOR
    
    IF max_gap > tomato_constraints.hook_interval:
        check_result.severity = "CRITICAL"
        check_result.issue = f"é’©å­é—´éš”è¿‡å¤§ï¼ˆ{max_gap}å­—ï¼Œä¸Šé™{tomato_constraints.hook_interval}å­—ï¼‰"
        check_result.fix_suggestions.APPEND("åœ¨æ— èŠæ®µè½æ’å…¥å†²çª/å‘ç°/è½¬æŠ˜")
        RETURN check_result
    END IF
    
    # æ£€æŸ¥2ï¼šä¿¡æ¯å¯†åº¦
    info_count = COUNT_NEW_INFO(scene_text)
    chars = LENGTH(scene_text)
    density = (info_count / chars) * 100  # æ¯100å­—çš„ä¿¡æ¯ç‚¹æ•°
    
    IF density < tomato_constraints.min_info_per_100:
        check_result.severity = "CRITICAL"
        check_result.issue = f"ä¿¡æ¯å¯†åº¦ä¸è¶³ï¼ˆ{density:.1f}/100å­—ï¼Œæœ€ä½{tomato_constraints.min_info_per_100}ï¼‰"
        check_result.fix_suggestions.APPEND("å‹ç¼©æå†™ï¼Œå¢åŠ å‰§æƒ…åŠ¨è¯")
        RETURN check_result
    END IF
    
    # æ£€æŸ¥3ï¼šæ®µè½é•¿åº¦
    paragraphs = SPLIT_PARAGRAPHS(scene_text)
    long_paras = FILTER(paragraphs, lambda p: LENGTH(p) > 150)
    
    IF LENGTH(long_paras) > LENGTH(paragraphs) * 0.3:
        check_result.severity = "WARNING"
        check_result.issue = f"{LENGTH(long_paras)}ä¸ªæ®µè½è¶…è¿‡150å­—"
        check_result.fix_suggestions.APPEND("æ‹†åˆ†é•¿æ®µè½")
    END IF
    
    # æ£€æŸ¥4ï¼šæ— èŠåº¦ï¼ˆè¿ç»­å¤šå°‘å­—æ²¡æœ‰"å…´å¥‹ç‚¹"ï¼‰
    boring_stretch = DETECT_BORING_STRETCH(scene_text)
    
    IF boring_stretch > tomato_constraints.max_boring_stretch:
        check_result.severity = "WARNING"
        check_result.issue = f"å­˜åœ¨{boring_stretch}å­—çš„å¹³æ·¡æ®µè½"
        check_result.fix_suggestions.APPEND("åœ¨å¹³æ·¡æ®µè½å¢åŠ å¾®å†²çªæˆ–æ„å¤–")
    END IF
    
    RETURN check_result
END FUNCTION
FUNCTION HAS_HOOK(para, context=NULL):
    """
    åˆ¤æ–­æ®µè½æ˜¯å¦æœ‰"é’©å­"ï¼ˆéœ€è¦ä¸Šä¸‹æ–‡ï¼‰
    
    æ”¹è¿›ï¼š
    1. ä¸ä»…çœ‹å…³é”®è¯ï¼Œè¿˜çœ‹æ˜¯å¦çœŸçš„æœ‰æ–°ä¿¡æ¯
    2. æ£€æŸ¥å¯¹è¯æ˜¯å¦ç©ºæ´
    3. æ£€æŸ¥å†²çªæ˜¯å¦å‡çº§
    """
    
    # ========== æ£€æŸ¥1ï¼šæ–°ä¿¡æ¯æ£€æµ‹ ==========
    # å‰§æƒ…åŠ¨è¯ï¼šå¿…é¡»ä¼´éšå…·ä½“åè¯
    plot_verbs = ["å‘ç°", "å¾—åˆ°", "å¤±å»", "é‡åˆ°", "å¬åˆ°", "çœ‹åˆ°"]
    
    FOR verb IN plot_verbs:
        IF verb IN para:
            # æ£€æŸ¥åŠ¨è¯åæ˜¯å¦æœ‰å…·ä½“å¯¹è±¡
            verb_pos = para.FIND(verb)
            after_verb = para[verb_pos+2:verb_pos+20]  # å–åŠ¨è¯å18ä¸ªå­—
            
            # å¦‚æœåé¢æœ‰å…·ä½“åè¯ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆé’©å­
            IF CONTAINS_CONCRETE_NOUN(after_verb):
                RETURN TRUE
            END IF
        END IF
    END FOR
    
    # ========== æ£€æŸ¥2ï¼šå†²çªæ ‡å¿— ==========
    conflict_markers = ["ä½†æ˜¯", "ä¸", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆå¯èƒ½", "ä¸å¯¹"]
    
    FOR marker IN conflict_markers:
        IF marker IN para:
            # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„å†²çªï¼Œè€Œéæ™®é€šè½¬æŠ˜
            # ç®€åŒ–åˆ¤æ–­ï¼šå¦‚æœæ®µè½è¾ƒé•¿ï¼ˆ>20å­—ï¼‰ï¼Œè®¤ä¸ºæœ‰å®è´¨å†…å®¹
            IF LENGTH(para) > 20:
                RETURN TRUE
            END IF
        END IF
    END FOR
    
    # ========== æ£€æŸ¥3ï¼šè½¬æŠ˜è¯ ==========
    turn_markers = ["çªç„¶", "è¿™æ—¶", "å¿½ç„¶", "æ²¡æƒ³åˆ°", "ç«Ÿç„¶"]
    IF ANY(marker IN para FOR marker IN turn_markers):
        RETURN TRUE
    END IF
    
    # ========== æ£€æŸ¥4ï¼šå¯¹è¯ï¼ˆä½†æ’é™¤ç©ºæ´å¯¹è¯ï¼‰==========
    IF CONTAINS_DIALOGUE(para):
        dialogue_content = EXTRACT_DIALOGUE(para)
        
        # æ’é™¤ç©ºæ´å¯¹è¯ï¼š"å—¯""å•Š""å“¦"ç­‰
        filler_words = ["å—¯", "å•Š", "å“¦", "å“ˆ", "å‘µ"]
        IF LENGTH(dialogue_content) <= 5 AND ANY(word IN dialogue_content FOR word IN filler_words):
            RETURN FALSE  # ç©ºæ´å¯¹è¯ä¸ç®—é’©å­
        END IF
        
        # æ’é™¤é‡å¤ä¿¡æ¯çš„å¯¹è¯
        IF context AND "previous_dialogues" IN context:
            IF IS_REPETITIVE_DIALOGUE(dialogue_content, context.previous_dialogues):
                RETURN FALSE
            END IF
        END IF
        
        RETURN TRUE  # æœ‰æ•ˆå¯¹è¯ç®—é’©å­
    END IF
    
    # ========== æ£€æŸ¥5ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰==========
    IF context:
        # æ£€æŸ¥æ˜¯å¦æœ‰æƒ…ç»ªå˜åŒ–
        IF "last_emotion" IN context:
            current_emotion = DETECT_EMOTION_INTENSITY(para)
            emotion_shift = ABS(current_emotion - context.last_emotion)
            
            IF emotion_shift > 20:  # æƒ…ç»ªå˜åŒ–>20
                RETURN TRUE
            END IF
        END IF
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°è§’è‰²ç™»åœº
        IF "known_characters" IN context:
            para_characters = EXTRACT_CHARACTER_NAMES(para)
            new_characters = SET_DIFFERENCE(para_characters, context.known_characters)
            
            IF LENGTH(new_characters) > 0:
                RETURN TRUE
            END IF
        END IF
    END IF
    
    RETURN FALSE
END FUNCTION

FUNCTION CONTAINS_CONCRETE_NOUN(text):
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å…·ä½“åè¯ï¼ˆè€Œéä»£è¯ï¼‰"""
    
    # æ’é™¤ä»£è¯
    pronouns = ["å®ƒ", "ä»–", "å¥¹", "è¿™", "é‚£", "ä»€ä¹ˆ", "ä¸œè¥¿"]
    IF ANY(pronoun IN text FOR pronoun IN pronouns):
        IF LENGTH(text) < 10:  # å¤ªçŸ­ä¸”åªæœ‰ä»£è¯
            RETURN FALSE
        END IF
    END IF
    
    # ç®€åŒ–åˆ¤æ–­ï¼šå¦‚æœæœ‰å®è¯ï¼ˆåè¯ï¼‰ï¼Œè®¤ä¸ºå…·ä½“
    # è¿™é‡Œç”¨é•¿åº¦ä½œä¸ºç®€åŒ–åˆ¤æ–­
    RETURN LENGTH(text) > 5
END FUNCTION

FUNCTION IS_REPETITIVE_DIALOGUE(dialogue, previous_dialogues):
    """æ£€æŸ¥å¯¹è¯æ˜¯å¦é‡å¤ä¹‹å‰çš„ä¿¡æ¯"""
    
    # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥æ˜¯å¦ä¸æœ€è¿‘3æ¡å¯¹è¯é«˜åº¦ç›¸ä¼¼
    recent = previous_dialogues[-3:] IF LENGTH(previous_dialogues) > 3 ELSE previous_dialogues
    
    FOR prev IN recent:
        similarity = CALCULATE_TEXT_SIMILARITY(dialogue, prev)
        IF similarity > 0.7:  # ç›¸ä¼¼åº¦>70%
            RETURN TRUE
        END IF
    END FOR
    
    RETURN FALSE
END FUNCTION

FUNCTION CALCULATE_TEXT_SIMILARITY(text1, text2):
    """è®¡ç®—ä¸¤æ®µæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–å®ç°ï¼‰"""
    
    # ç®€åŒ–ï¼šè®¡ç®—å…±åŒå­—ç¬¦æ¯”ä¾‹
    chars1 = SET(text1)
    chars2 = SET(text2)
    
    intersection = SET_INTERSECTION(chars1, chars2)
    union = SET_UNION(chars1, chars2)
    
    IF LENGTH(union) == 0:
        RETURN 0
    END IF
    
    RETURN LENGTH(intersection) / LENGTH(union)
END FUNCTION

FUNCTION DETECT_BORING_STRETCH(text):
    """æ£€æµ‹æœ€é•¿çš„æ— èŠæ®µè½ï¼ˆæ— æ–°ä¿¡æ¯çš„è¿ç»­æ–‡å­—ï¼‰"""
    
    paragraphs = SPLIT_PARAGRAPHS(text)
    current_boring = 0
    max_boring = 0
    
    FOR para IN paragraphs:
        IF NOT HAS_HOOK(para):
            current_boring += LENGTH(para)
            max_boring = MAX(max_boring, current_boring)
        ELSE:
            current_boring = 0
        END IF
    END FOR
    
    RETURN max_boring
END FUNCTION
```

### 4.4.2 ç•ªèŒ„é£æ ¼ä¿®å¤
```python
FUNCTION REWRITE_WITH_TOMATO_BOOST(scene_plan, tomato_check, parsed_data):
    """
    é‡å†™åœºæ™¯ï¼Œæ³¨å…¥ç•ªèŒ„å…ƒç´ 
    """
    
    PRINT f"[TOMATO BOOST] ä¿®å¤ï¼š{tomato_check.issue}"
    
    # æ ¹æ®é—®é¢˜ç±»å‹ä¿®å¤
    IF "é’©å­é—´éš”" IN tomato_check.issue:
        # ç­–ç•¥ï¼šåœ¨å¹³æ·¡æ®µè½æ’å…¥å¾®å†²çª
        scene_text = WRITE_SCENE_WITH_MORE_HOOKS(scene_plan, parsed_data)
    
    ELSE IF "ä¿¡æ¯å¯†åº¦" IN tomato_check.issue:
        # ç­–ç•¥ï¼šå‹ç¼©æå†™ï¼Œå¢åŠ åŠ¨ä½œ
        scene_text = WRITE_SCENE_WITH_HIGH_DENSITY(scene_plan, parsed_data)
    
    ELSE:
        # é»˜è®¤ï¼šå¸¸è§„é‡å†™
        scene_text = WRITE_SCENE_BY_TYPE(scene_plan, parsed_data, "", INIT_MONITORS())
    END IF
    
    RETURN scene_text
END FUNCTION

FUNCTION WRITE_SCENE_WITH_MORE_HOOKS(scene_plan, parsed_data):
    """å†™ä½œåœºæ™¯æ—¶å¼ºåˆ¶æ’å…¥é’©å­"""
    
    scene_text = ""
    hook_interval = SCENE_TYPES[scene_plan.type].tomato_constraints.hook_interval
    current_length = 0
    
    # ä½¿ç”¨æ ‡å‡†æ¨¡å¼å†™ä½œï¼Œä½†æ¯Nå­—å¼ºåˆ¶æ’å…¥é’©å­
    units = DECOMPOSE_SCENE_TO_UNITS(scene_plan.scene_idx, parsed_data, {})
    
    FOR unit IN units:
        unit_text = WRITE_UNIT_BY_TYPE(unit, "BRIEF", parsed_data)
        scene_text += unit_text
        current_length += LENGTH(unit_text)
        
        # æ¯åˆ°è¾¾é’©å­é—´éš”ï¼Œå¼ºåˆ¶æ’å…¥å¾®é’©å­
        IF current_length >= hook_interval:
            micro_hook = GENERATE_MICRO_HOOK(scene_plan, parsed_data)
            scene_text += "\n\n" + micro_hook
            current_length = 0
        END IF
    END FOR
    
    RETURN scene_text
END FUNCTION

FUNCTION GENERATE_MICRO_HOOK(scene_plan, parsed_data):
    """ç”Ÿæˆå¾®é’©å­ï¼ˆå°å†²çª/å°å‘ç°/å°æ„å¤–ï¼‰"""
    
    hook_types = [
        "MINI_DISCOVERY",    # å°å‘ç°ï¼š"ä»–æ³¨æ„åˆ°..."
        "MINI_CONFLICT",     # å°å†²çªï¼š"å¯¹æ–¹çš„æ€åº¦å˜äº†"
        "MINI_REACTION",     # å°ååº”ï¼š"ä»–çš±äº†çš±çœ‰"
        "MINI_QUESTION"      # å°ç–‘é—®ï¼š"è¿™ä¸å¯¹åŠ²"
    ]
    
    hook_type = RANDOM_CHOICE(hook_types)
    protagonist = parsed_data.characters.protagonist.name
    
    SWITCH hook_type:
        CASE "MINI_DISCOVERY":
            RETURN f"{protagonist}æ³¨æ„åˆ°ä¸€ä¸ªç»†èŠ‚ã€‚"
        
        CASE "MINI_CONFLICT":
            RETURN f"æ°”æ°›æœ‰äº›å¾®å¦™ã€‚"
        
        CASE "MINI_REACTION":
            RETURN f"{protagonist}çœ‰å¤´å¾®è¹™ã€‚"
        
        CASE "MINI_QUESTION":
            RETURN f"ä¸å¯¹åŠ²ã€‚"
    END SWITCH
END FUNCTION
```
### 4.4.3 çˆ½ç‚¹æ³¨å…¥

```python
FUNCTION INJECT_COOL_POINT(scene_text, cool_type, parsed_data):
    """
    åœ¨åœºæ™¯ä¸­æ³¨å…¥çˆ½ç‚¹
    """
    
    PRINT f"[COOL INJECTION] æ³¨å…¥çˆ½ç‚¹ï¼š{cool_type}"
    
    # ç”Ÿæˆçˆ½ç‚¹æ–‡æœ¬ï¼ˆå‚è€ƒv3.1çš„çˆ½ç‚¹ç”Ÿæˆï¼‰
    cool_text = GENERATE_COOL_POINT_TEXT(cool_type, parsed_data)
    
    # æ‰¾åˆ°åˆé€‚çš„æ’å…¥ä½ç½®ï¼ˆ70%å¤„ï¼‰
    insert_pos = ROUND(LENGTH(scene_text) * 0.7)
    para_end = FIND_NEXT(scene_text, "\n\n", insert_pos)
    
    IF para_end > 0:
        RETURN scene_text[:para_end] + "\n\n" + cool_text + "\n\n" + scene_text[para_end:]
    ELSE:
        RETURN scene_text + "\n\n" + cool_text
    END IF
END FUNCTION

FUNCTION GENERATE_COOL_POINT_TEXT(cool_type, parsed_data):
    """ç”Ÿæˆçˆ½ç‚¹æ–‡æœ¬"""
    
    protagonist = parsed_data.characters.protagonist.name
    
    SWITCH cool_type:
        CASE "æ‰“è„¸çˆ½":
            RETURN f"å¯¹æ–¹çš„è¡¨æƒ…åƒµä½äº†ã€‚\n\næ²¡äººæƒ³åˆ°{protagonist}ä¼šè¿™ä¹ˆè¯´ã€‚"
        
        CASE "è£…é€¼çˆ½":
            RETURN f"{protagonist}æ·¡æ·¡åœ°è¯´å‡ºäº†ç­”æ¡ˆã€‚\n\nå…¨åœºå¯‚é™ã€‚"
        
        CASE "å¤ä»‡çˆ½":
            RETURN f"è¯¥è¿˜çš„ï¼Œç»ˆäºè¿˜äº†ã€‚\n\n{protagonist}è½¬èº«ç¦»å¼€ã€‚"
        
        CASE "å‡çº§çˆ½":
            RETURN f"çªç ´äº†ã€‚\n\n{protagonist}çå¼€çœ¼ï¼Œæ„Ÿå—ç€ä½“å†…æ¶ŒåŠ¨çš„åŠ›é‡ã€‚"
        
        CASE "åæ€çˆ½":
            RETURN f"å°±åœ¨æ‰€æœ‰äººä»¥ä¸º{protagonist}å®Œäº†çš„æ—¶å€™â€”â€”\n\nä»–ç¬‘äº†ã€‚"
    END SWITCH
END FUNCTION

```

---

## Â§5 æ–‡å­¦æ€§è¯Šæ–­ç³»ç»Ÿ | æ¨¡æ‹Ÿè¯»è€…ä½“éªŒ

### 5.1 è¯»è€…ä½“éªŒæ¨¡æ‹Ÿå™¨

```python
FUNCTION DIAGNOSE_LITERARY_QUALITY(chapter_content, parsed_data, plan):
    """
    æ–‡å­¦æ€§è¯Šæ–­ï¼ˆæ ¸å¿ƒæ”¹è¿›ï¼‰
    
    ä¸çœ‹æŠ€æœ¯æŒ‡æ ‡ï¼Œæ¨¡æ‹Ÿè¯»è€…ä½“éªŒ
    """
    
    diagnosis = {
        "literary_issues": [],  # æ–‡å­¦æ€§é—®é¢˜
        "technical_metrics": {},  # æŠ€æœ¯æŒ‡æ ‡ï¼ˆå‚è€ƒï¼‰
        "reader_experience": {},  # è¯»è€…ä½“éªŒè¯„ä¼°
        "needs_rewrite": FALSE,
        "needs_fix": FALSE,
        "fixes": []
    }
    
    # ========== ç¬¬ä¸€å±‚ï¼šè¯»è€…ç†è§£åº¦æ£€æŸ¥ ==========
    understanding_check = CHECK_READER_UNDERSTANDING(chapter_content, parsed_data, plan)
    
    IF NOT understanding_check.can_follow:
        diagnosis.literary_issues.APPEND({
            "type": "CONFUSION",
            "severity": "CRITICAL",
            "description": understanding_check.confusion_points,
            "impact": "è¯»è€…ä¼šå›°æƒ‘",
            "fix_strategy": "REWRITE_CONFUSING_PARTS"
        })
        diagnosis.needs_rewrite = TRUE
    END IF
    
    # ========== ç¬¬äºŒå±‚ï¼šåœºæ™¯ç›®æ ‡è¾¾æˆæ£€æŸ¥ ==========
    FOR scene_plan IN plan.scenes:
        scene_content = EXTRACT_SCENE_FROM_CHAPTER(chapter_content, scene_plan.scene_idx)
        
        goal_achieved = CHECK_LITERARY_GOAL_ACHIEVED(scene_content, scene_plan.literary_goal, parsed_data)
        
        IF NOT goal_achieved.success:
            diagnosis.literary_issues.APPEND({
                "type": "GOAL_NOT_MET",
                "severity": "CRITICAL",
                "scene_idx": scene_plan.scene_idx,
                "description": f"åœºæ™¯{scene_plan.scene_idx}æœªè¾¾æˆç›®æ ‡ï¼š{scene_plan.literary_goal}",
                "evidence": goal_achieved.evidence,
                "fix_strategy": "REWRITE_SCENE"
            })
            diagnosis.needs_rewrite = TRUE
        END IF
    END FOR
    
    # ========== ç¬¬ä¸‰å±‚ï¼šè§’è‰²è¡Œä¸ºåˆç†æ€§æ£€æŸ¥ ==========
    ooc_check = CHECK_OOC_BEHAVIORS(chapter_content, parsed_data)
    
    IF ooc_check.has_ooc:
        diagnosis.literary_issues.APPEND({
            "type": "OOC",
            "severity": "CRITICAL",
            "description": ooc_check.violations,
            "impact": "è§’è‰²è¡Œä¸ºä¸ç¬¦åˆäººè®¾",
            "fix_strategy": "REWRITE_OOC_PARTS"
        })
        diagnosis.needs_rewrite = TRUE
    END IF
    
    # ========== ç¬¬å››å±‚ï¼šå¯¹è¯è´¨é‡æ£€æŸ¥ ==========
    dialogues = EXTRACT_ALL_DIALOGUES(chapter_content)
    ineffective_dialogues = []
    
    FOR dialogue IN dialogues:
        IF NOT IS_GOOD_DIALOGUE(dialogue):
            ineffective_dialogues.APPEND(dialogue)
        END IF
    END FOR
    
    IF LENGTH(ineffective_dialogues) > LENGTH(dialogues) * 0.3:
        # è¶…è¿‡30%çš„å¯¹è¯æ— æ•ˆ
        diagnosis.literary_issues.APPEND({
            "type": "DIALOGUE_QUALITY",
            "severity": "WARNING",
            "description": f"{LENGTH(ineffective_dialogues)}å¤„å¯¹è¯æ— æ•ˆï¼ˆä¸æ¨è¿›å‰§æƒ…/ä¸æ­ç¤ºè§’è‰²ï¼‰",
            "examples": ineffective_dialogues[:3],
            "fix_strategy": "IMPROVE_OR_DELETE_DIALOGUES"
        })
        diagnosis.needs_fix = TRUE
        diagnosis.fixes.APPEND("dialogue_quality")
    END IF
    
    # ========== ç¬¬äº”å±‚ï¼šç”»é¢æ„Ÿæ£€æŸ¥ ==========
    imagery_score = CALCULATE_IMAGERY_SCORE(chapter_content)
    
    IF imagery_score < 5:  # ç”»é¢æ„Ÿè¯„åˆ†<5/10
        diagnosis.literary_issues.APPEND({
            "type": "LACK_IMAGERY",
            "severity": "WARNING",
            "description": "ç¼ºå°‘å…·ä½“ç”»é¢æ„Ÿï¼Œå¤šä¸ºæŠ½è±¡æè¿°",
            "fix_strategy": "ADD_SENSORY_DETAILS"
        })
        diagnosis.needs_fix = TRUE
        diagnosis.fixes.APPEND("imagery")
    END IF
    
    # ========== ç¬¬å…­å±‚ï¼šæƒ…ç»ªé€’è¿›æ£€æŸ¥ ==========
    emotion_flow = ANALYZE_EMOTION_FLOW(chapter_content, parsed_data)
    
    IF emotion_flow.is_flat:
        diagnosis.literary_issues.APPEND({
            "type": "FLAT_EMOTION",
            "severity": "WARNING",
            "description": "æƒ…ç»ªæ²¡æœ‰é€’è¿›æˆ–è½¬æŠ˜",
            "fix_strategy": "ADD_EMOTION_TURNS"
        })
        diagnosis.needs_fix = TRUE
        diagnosis.fixes.APPEND("emotion_flow")
    END IF
    
	
	    # ========== æ–°å¢ï¼šç¬¬ä¸ƒå±‚ - çˆ½åº¦æ£€æŸ¥ï¼ˆç•ªèŒ„å¿…å¤‡ï¼‰==========
    cool_check = CHECK_COOL_POINT_DELIVERY(chapter_content, plan)
    
    IF cool_check.coolness_score < 5:  # çˆ½åº¦<5/10
        diagnosis.literary_issues.APPEND({
            "type": "LOW_COOLNESS",
            "severity": "WARNING",
            "description": f"çˆ½åº¦ä¸è¶³ï¼ˆ{cool_check.coolness_score}/10ï¼‰ï¼Œç¼ºå°‘é«˜æ½®ç‚¹",
            "missing_cool_points": cool_check.missing_cool_points,
            "fix_strategy": "åœ¨å…³é”®åœºæ™¯å¢åŠ æ‰“è„¸/è£…é€¼/åè½¬ç­‰çˆ½ç‚¹"
        })
        diagnosis.needs_fix = TRUE
        diagnosis.fixes.APPEND("coolness")
    END IF
    
    # ========== æ–°å¢ï¼šç¬¬å…«å±‚ - ç•ªèŒ„é£æ ¼å…¨å±€æ£€æŸ¥ ==========
    tomato_global_check = CHECK_TOMATO_STYLE_GLOBAL(chapter_content, plan)
    
    IF tomato_global_check.has_issues:
        FOR issue IN tomato_global_check.issues:
            diagnosis.literary_issues.APPEND({
                "type": "TOMATO_STYLE",
                "severity": issue.severity,
                "description": issue.description,
                "fix_strategy": issue.fix_strategy
            })
            
            IF issue.severity == "CRITICAL":
                diagnosis.needs_fix = TRUE
            END IF
        END FOR
    END IF
    
    # ========== æŠ€æœ¯æŒ‡æ ‡ï¼ˆä»…ä½œå‚è€ƒï¼‰==========
    diagnosis.technical_metrics = {
        "word_count": LENGTH(chapter_content),
        "dialogue_ratio": CALCULATE_DIALOGUE_RATIO(chapter_content),
        "info_density": CALCULATE_INFO_DENSITY(chapter_content),
        "avg_para_length": AVG_PARAGRAPH_LENGTH(chapter_content)
    }
    
    # æŠ€æœ¯æŒ‡æ ‡ä¸¥é‡åç¦»æ—¶è®°å½•ï¼ˆä½†ä¸ä½œä¸ºé‡å†™ä¾æ®ï¼‰
    IF diagnosis.technical_metrics.word_count < 1500:
        diagnosis.literary_issues.APPEND({
            "type": "WORD_COUNT_LOW",
            "severity": "WARNING",
            "description": "å­—æ•°è¿‡å°‘å¯èƒ½å¯¼è‡´ä¿¡æ¯ä¸è¶³",
            "fix_strategy": "EXPAND_KEY_SCENES"
        })
    END IF
    
    RETURN diagnosis
END FUNCTION


FUNCTION CHECK_COOL_POINT_DELIVERY(chapter_content, plan):
    """æ£€æŸ¥çˆ½ç‚¹äº¤ä»˜æƒ…å†µ"""
    
    result = {
        "coolness_score": 5.0,
        "missing_cool_points": []
    }
    
    # æ£€æŸ¥è®¡åˆ’ä¸­çš„çˆ½ç‚¹æ˜¯å¦éƒ½å®ç°äº†
    FOR scene_idx, cool_type IN plan.cool_point_plan.ITEMS():
        scene_content = EXTRACT_SCENE_FROM_CHAPTER(chapter_content, scene_idx)
        
        IF NOT DETECT_COOL_POINT_IN_SCENE(scene_content, cool_type):
            result.missing_cool_points.APPEND({
                "scene_idx": scene_idx,
                "cool_type": cool_type
            })
            result.coolness_score -= 2.0
        END IF
    END FOR
    
    # é¢å¤–åŠ åˆ†ï¼šæ£€æµ‹åˆ°æœªè®¡åˆ’çš„çˆ½ç‚¹
    bonus_cool_points = DETECT_UNPLANNED_COOL_POINTS(chapter_content)
    result.coolness_score += LENGTH(bonus_cool_points) * 0.5
    
    result.coolness_score = CLAMP(result.coolness_score, 0, 10)
    
    RETURN result
END FUNCTION

FUNCTION CHECK_TOMATO_STYLE_GLOBAL(chapter_content, plan):
    """å…¨å±€ç•ªèŒ„é£æ ¼æ£€æŸ¥"""
    
    result = {
        "has_issues": FALSE,
        "issues": []
    }
    
    # æ£€æŸ¥1ï¼šå…¨æ–‡é’©å­å¯†åº¦
    total_length = LENGTH(chapter_content)
    hook_count = COUNT_HOOKS_IN_TEXT(chapter_content)
    avg_hook_interval = total_length / MAX(hook_count, 1)
    
    IF avg_hook_interval > 600:
        result.has_issues = TRUE
        result.issues.APPEND({
            "severity": "CRITICAL",
            "description": f"å…¨æ–‡å¹³å‡{avg_hook_interval:.0f}å­—ä¸€ä¸ªé’©å­ï¼ˆæ ‡å‡†â‰¤600å­—ï¼‰",
            "fix_strategy": "å¢åŠ å¾®å†²çªã€å°å‘ç°æˆ–æ„å¤–"
        })
    END IF
    
    # æ£€æŸ¥2ï¼šå¯¹è¯å æ¯”ï¼ˆç•ªèŒ„å°è¯´æ ¸å¿ƒæŒ‡æ ‡ï¼‰
    dialogue_ratio = CALCULATE_DIALOGUE_RATIO(chapter_content)
    
    IF dialogue_ratio < 0.30:
        result.has_issues = TRUE
        result.issues.APPEND({
            "severity": "CRITICAL",
            "description": f"å¯¹è¯å æ¯”{dialogue_ratio*100:.1f}%ï¼Œä½äºç•ªèŒ„æ ‡å‡†ï¼ˆ30%+ï¼‰",
            "fix_strategy": "å°†æå†™æ”¹ä¸ºå¯¹è¯ï¼Œæˆ–å¢åŠ è§’è‰²äº’åŠ¨"
        })
    END IF
    
    # æ£€æŸ¥3ï¼šæ®µè½é•¿åº¦ï¼ˆç•ªèŒ„å°è¯´è¦æ±‚çŸ­æ®µï¼‰
    long_para_ratio = COUNT_LONG_PARAGRAPHS(chapter_content) / COUNT_PARAGRAPHS(chapter_content)
    
    IF long_para_ratio > 0.3:
        result.has_issues = TRUE
        result.issues.APPEND({
            "severity": "WARNING",
            "description": f"{long_para_ratio*100:.0f}%çš„æ®µè½è¶…è¿‡150å­—",
            "fix_strategy": "æ‹†åˆ†é•¿æ®µè½"
        })
    END IF
    
    RETURN result
END FUNCTION

FUNCTION COUNT_HOOKS_IN_TEXT(text):
    """ç»Ÿè®¡å…¨æ–‡é’©å­æ•°é‡"""
    count = 0
    FOR para IN SPLIT_PARAGRAPHS(text):
        IF HAS_HOOK(para):
            count += 1
        END IF
    END FOR
    RETURN count
END FUNCTION

```

### 5.2 è¯»è€…ç†è§£åº¦æ£€æŸ¥

```python
FUNCTION CHECK_READER_UNDERSTANDING(chapter_content, parsed_data, plan):
    """
    æ£€æŸ¥è¯»è€…æ˜¯å¦èƒ½ç†è§£æ•…äº‹
    
    æ ¸å¿ƒé—®é¢˜ï¼š
    1. è¯»è€…çŸ¥é“WHOåœ¨WHEREåšWHATå—ï¼Ÿ
    2. è¯»è€…ç†è§£è§’è‰²çš„åŠ¨æœºå—ï¼Ÿ
    3. è¯»è€…èƒ½è·Ÿä¸Šå‰§æƒ…å—ï¼Ÿ
    """
    
    check_result = {
        "can_follow": TRUE,
        "confusion_points": []
    }
    
    # æ£€æŸ¥1ï¼šå¼€ç¯‡æ˜¯å¦äº¤ä»£WHO/WHERE
    first_100_chars = chapter_content[:100]
    
    protagonist_name = parsed_data.characters.protagonist.GET("name", "")
    location = parsed_data.context.GET("location", "")
    
    IF protagonist_name NOT IN first_100_chars:
        check_result.confusion_points.APPEND("å¼€ç¯‡æœªäº¤ä»£ä¸»è§’æ˜¯è°")
        check_result.can_follow = FALSE
    END IF
    
    IF location NOT IN first_100_chars[:200]:
        check_result.confusion_points.APPEND("å¼€ç¯‡æœªäº¤ä»£åœ°ç‚¹")
        # è¿™ä¸ªä¸ç®—CRITICALï¼Œåªæ˜¯WARNING
    END IF
    
    # æ£€æŸ¥2ï¼šè§’è‰²åŠ¨ä½œæ˜¯å¦æœ‰åŠ¨æœº
    unexplained_actions = FIND_UNEXPLAINED_ACTIONS(chapter_content, parsed_data)
    
    IF LENGTH(unexplained_actions) > 2:
        check_result.confusion_points.APPEND(f"æœ‰{LENGTH(unexplained_actions)}å¤„åŠ¨ä½œç¼ºå°‘åŠ¨æœº")
        check_result.can_follow = FALSE
    END IF
    
    # æ£€æŸ¥3ï¼šåœºæ™¯è·³è·ƒæ˜¯å¦çªå…€
    scenes = DETECT_SCENES(chapter_content)
    
    FOR i = 1 TO LENGTH(scenes) - 1:
        prev_scene = scenes[i-1]
        curr_scene = scenes[i]
        
        IF IS_ABRUPT_TRANSITION(prev_scene, curr_scene):
            check_result.confusion_points.APPEND(f"åœºæ™¯{i}åˆ°åœºæ™¯{i+1}è·³è·ƒçªå…€")
        END IF
    END FOR
    
    RETURN check_result
END FUNCTION

FUNCTION FIND_UNEXPLAINED_ACTIONS(text, parsed_data):
    """æ‰¾åˆ°ç¼ºå°‘åŠ¨æœºçš„åŠ¨ä½œ"""
    
    # æå–æ‰€æœ‰åŠ¨ä½œå¥
    action_sentences = EXTRACT_ACTION_SENTENCES(text)
    
    unexplained = []
    
    FOR sentence IN action_sentences:
        # æ£€æŸ¥å‰åæ˜¯å¦æœ‰åŠ¨æœºè¯´æ˜
        context = GET_SENTENCE_CONTEXT(text, sentence, before=2, after=1)
        
        has_motivation = (
            CONTAINS_MOTIVATION_KEYWORDS(context) OR
            CAN_INFER_FROM_CONTEXT(context, parsed_data)
        )
        
        IF NOT has_motivation AND IS_MAJOR_ACTION(sentence):
            unexplained.APPEND(sentence)
        END IF
    END FOR
    
    RETURN unexplained
END FUNCTION
```

### 5.3 æ–‡å­¦ç›®æ ‡è¾¾æˆæ£€æŸ¥

```python				
FUNCTION CHECK_LITERARY_GOAL_ACHIEVED(scene_content, goal, parsed_data):
    """
    æ£€æŸ¥åœºæ™¯æ˜¯å¦è¾¾æˆæ–‡å­¦ç›®æ ‡ï¼ˆæ”¹è¿›ç‰ˆï¼šå¯å‘å¼è§„åˆ™ï¼‰
    
    æ‰¿è®¤Claudeå±€é™ï¼š
    - ä¸è¿½æ±‚å®Œç¾çš„è¯­ä¹‰ç†è§£
    - ç”¨å¯å‘å¼è§„åˆ™æ£€æŸ¥"æ˜¯å¦æœ‰å°è¯•è¾¾æˆç›®æ ‡çš„è¯æ®"
    """
    
    result = {
        "success": FALSE,
        "evidence": ""
    }
    
    goal_lower = goal.LOWER()
    
    # ========== ç›®æ ‡ç±»å‹1ï¼šä¿¡æ¯ä¼ è¾¾ç±» ==========
    IF "ç†è§£" IN goal_lower OR "çŸ¥é“" IN goal_lower:
        # æ£€æŸ¥æ˜¯å¦æœ‰è§£é‡Šæ€§å†…å®¹
        has_explanation = CHECK_FOR_EXPLANATION(scene_content)
        
        IF has_explanation.found:
            result.success = TRUE
            result.evidence = f"åœºæ™¯åŒ…å«è§£é‡Šæ€§å†…å®¹ï¼š{has_explanation.example}"
        ELSE:
            result.evidence = "åœºæ™¯ç¼ºå°‘è§£é‡Šæ€§å†…å®¹ï¼ˆå› æœè¯ã€å†…å¿ƒç‹¬ç™½ç­‰ï¼‰"
        END IF
    
    # ========== ç›®æ ‡ç±»å‹2ï¼šäººè®¾å±•ç¤ºç±» ==========
    ELSE IF "å±•ç¤º" IN goal_lower OR "ä½“ç°" IN goal_lower:
        # æå–è¦å±•ç¤ºçš„ç‰¹è´¨
        trait = EXTRACT_TRAIT_FROM_GOAL(goal_lower)
        
        IF trait:
            # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…è¡Œä¸º
            has_behavior = CHECK_BEHAVIOR_FOR_TRAIT(scene_content, trait, parsed_data)
            
            IF has_behavior.found:
                result.success = TRUE
                result.evidence = f"åœºæ™¯æœ‰ä½“ç°'{trait}'çš„è¡Œä¸ºï¼š{has_behavior.example}"
            ELSE:
                result.evidence = f"åœºæ™¯ä¸­æœªæ‰¾åˆ°ä½“ç°'{trait}'çš„å…·ä½“è¡Œä¸º"
            END IF
        ELSE:
            # æ— æ³•æå–ç‰¹è´¨ï¼Œé»˜è®¤é€šè¿‡
            result.success = TRUE
            result.evidence = "ç›®æ ‡è¾ƒæŠ½è±¡ï¼Œæ— æ³•ç²¾ç¡®æ£€æŸ¥"
        END IF
    
    # ========== ç›®æ ‡ç±»å‹3ï¼šå‰§æƒ…æ¨è¿›ç±» ==========
    ELSE IF "æ¨è¿›" IN goal_lower:
        # æ£€æŸ¥çŠ¶æ€æ˜¯å¦æ”¹å˜
        has_change = CHECK_STATE_CHANGE(scene_content, parsed_data)
        
        IF has_change.found:
            result.success = TRUE
            result.evidence = f"åœºæ™¯æœ‰çŠ¶æ€å˜åŒ–ï¼š{has_change.description}"
        ELSE:
            result.evidence = "åœºæ™¯ç¼ºå°‘æ˜æ˜¾çš„çŠ¶æ€å˜åŒ–ï¼ˆä¿¡æ¯/å…³ç³»/ä½ç½®ï¼‰"
        END IF
    
    # ========== ç›®æ ‡ç±»å‹4ï¼šæƒ…æ„Ÿç›®æ ‡ ==========
    ELSE IF "æ„Ÿå—" IN goal_lower OR "æ°›å›´" IN goal_lower:
        # æ£€æŸ¥æƒ…ç»ªå¼ºåº¦
        emotion_score = DETECT_EMOTION_INTENSITY(scene_content)
        
        IF emotion_score > 60:
            result.success = TRUE
            result.evidence = f"åœºæ™¯æƒ…ç»ªå¼ºåº¦è¶³å¤Ÿï¼ˆ{emotion_score}/100ï¼‰"
        ELSE:
            result.evidence = f"åœºæ™¯æƒ…ç»ªå¼ºåº¦ä¸è¶³ï¼ˆ{emotion_score}/100ï¼‰"
        END IF
    
    # ========== é»˜è®¤ï¼šå…³é”®è¯æ£€æŸ¥ ==========
    ELSE:
        # æå–ç›®æ ‡å…³é”®è¯
        keywords = EXTRACT_KEYWORDS(goal)
        matched = [kw FOR kw IN keywords IF kw IN scene_content]
        
        IF LENGTH(matched) >= LENGTH(keywords) * 0.6:  # 60%å…³é”®è¯åŒ¹é…
            result.success = TRUE
            result.evidence = f"å…³é”®è¯åŒ¹é…ç‡{LENGTH(matched)/LENGTH(keywords)*100:.0f}%"
        ELSE:
            result.evidence = f"å…³é”®è¯åŒ¹é…ä¸è¶³ï¼ˆ{LENGTH(matched)}/{LENGTH(keywords)}ï¼‰"
        END IF
    END IF
    
    RETURN result
END FUNCTION

# ========== è¾…åŠ©æ£€æŸ¥å‡½æ•° ==========

FUNCTION CHECK_FOR_EXPLANATION(text):
    """æ£€æŸ¥æ˜¯å¦æœ‰è§£é‡Šæ€§å†…å®¹"""
    
    # å› æœè¯
    causal_words = ["å› ä¸º", "æ‰€ä»¥", "ä¸ºäº†", "å¯¼è‡´", "åŸå› æ˜¯"]
    
    FOR word IN causal_words:
        IF word IN text:
            # æå–åŒ…å«è¯¥è¯çš„å¥å­ä½œä¸ºç¤ºä¾‹
            example = EXTRACT_SENTENCE_WITH_WORD(text, word)
            RETURN {"found": TRUE, "example": example[:50]}
        END IF
    END FOR
    
    # å†…å¿ƒç‹¬ç™½ï¼ˆé€šå¸¸ç”¨äºè§£é‡ŠåŠ¨æœºï¼‰
    IF "ä»–æƒ³" IN text OR "å¥¹æƒ³" IN text OR "å¿ƒé‡Œ" IN text:
        example = EXTRACT_INNER_MONOLOGUE(text)
        IF LENGTH(example) > 10:
            RETURN {"found": TRUE, "example": example[:50]}
        END IF
    END IF
    
    RETURN {"found": FALSE, "example": ""}
END FUNCTION

FUNCTION EXTRACT_TRAIT_FROM_GOAL(goal):
    """ä»ç›®æ ‡ä¸­æå–äººè®¾ç‰¹è´¨"""
    
    # å¸¸è§äººè®¾ç‰¹è´¨
    traits = ["è°¨æ…", "å†²åŠ¨", "è´ªå©ª", "å–„è‰¯", "ç‹¡çŒ¾", "å‹‡æ•¢", "æ‡¦å¼±", "éª„å‚²", "è°¦è™š"]
    
    FOR trait IN traits:
        IF trait IN goal:
            RETURN trait
        END IF
    END FOR
    
    # å¦‚æœæ²¡æœ‰ç›´æ¥ç‰¹è´¨è¯ï¼Œå°è¯•æ¨æ–­
    IF "å°å¿ƒ" IN goal OR "è­¦æƒ•" IN goal:
        RETURN "è°¨æ…"
    ELSE IF "æœæ–­" IN goal OR "ä¸çŠ¹è±«" IN goal:
        RETURN "å†²åŠ¨"
    END IF
    
    RETURN NULL
END FUNCTION

FUNCTION CHECK_BEHAVIOR_FOR_TRAIT(text, trait, parsed_data):
    """æ£€æŸ¥æ˜¯å¦æœ‰ä½“ç°ç‰¹è´¨çš„è¡Œä¸º"""
    
    protagonist_name = parsed_data.characters.protagonist.GET("name", "ä¸»è§’")
    
    # æ ¹æ®ç‰¹è´¨æŸ¥æ‰¾åŒ¹é…è¡Œä¸º
    SWITCH trait:
        CASE "è°¨æ…":
            keywords = ["è§‚å¯Ÿ", "ç­‰å¾…", "è¯•æ¢", "åé€€", "ç¡®è®¤", "å°å¿ƒ"]
        
        CASE "å†²åŠ¨":
            keywords = ["ç«‹åˆ»", "ç›´æ¥", "æ²¡æƒ³", "ç®¡ä¸äº†", "å†²"]
        
        CASE "è´ªå©ª":
            keywords = ["æƒ³è¦", "å…¨éƒ¨", "æ›´å¤š", "ä¸å¤Ÿ", "çœ¼ç›å‘äº®"]
        
        CASE "å–„è‰¯":
            keywords = ["å¸®", "æ•‘", "å¯æ€œ", "ä¸å¿", "åœ¨ä¹"]
        
        DEFAULT:
            keywords = [trait]  # é»˜è®¤æŸ¥æ‰¾ç‰¹è´¨è¯æœ¬èº«
    END SWITCH
    
    # æŸ¥æ‰¾ä¸»è§’æ‰§è¡Œçš„åŒ¹é…è¡Œä¸º
    FOR keyword IN keywords:
        sentences = SPLIT_SENTENCES(text)
        
        FOR sentence IN sentences:
            IF protagonist_name IN sentence AND keyword IN sentence:
                RETURN {"found": TRUE, "example": sentence[:50]}
            END IF
        END FOR
    END FOR
    
    RETURN {"found": FALSE, "example": ""}
END FUNCTION

FUNCTION CHECK_STATE_CHANGE(text, parsed_data):
    """æ£€æŸ¥æ˜¯å¦æœ‰çŠ¶æ€å˜åŒ–"""
    
    changes = []
    
    # æ£€æŸ¥1ï¼šä¿¡æ¯å˜åŒ–ï¼ˆå‘ç°æ–°ä¿¡æ¯ï¼‰
    info_keywords = ["å‘ç°", "çŸ¥é“", "å¾—çŸ¥", "å¬è¯´", "çœ‹åˆ°"]
    FOR keyword IN info_keywords:
        IF keyword IN text:
            changes.APPEND(f"ä¿¡æ¯å˜åŒ–ï¼ˆ{keyword}ï¼‰")
            BREAK
        END IF
    END FOR
    
    # æ£€æŸ¥2ï¼šå…³ç³»å˜åŒ–
    relationship_keywords = ["æˆä¸º", "å†³è£‚", "å’Œè§£", "ä¿¡ä»»", "æ€€ç–‘"]
    FOR keyword IN relationship_keywords:
        IF keyword IN text:
            changes.APPEND(f"å…³ç³»å˜åŒ–ï¼ˆ{keyword}ï¼‰")
            BREAK
        END IF
    END FOR
    
    # æ£€æŸ¥3ï¼šä½ç½®å˜åŒ–
    location_keywords = ["æ¥åˆ°", "ç¦»å¼€", "è¿›å…¥", "èµ°å‡º", "åˆ°è¾¾"]
    FOR keyword IN location_keywords:
        IF keyword IN text:
            changes.APPEND(f"ä½ç½®å˜åŒ–ï¼ˆ{keyword}ï¼‰")
            BREAK
        END IF
    END FOR
    
    # æ£€æŸ¥4ï¼šç‰©å“å˜åŒ–
    item_keywords = ["å¾—åˆ°", "å¤±å»", "æ¡åˆ°", "ä¸¢å¤±", "è·å¾—"]
    FOR keyword IN item_keywords:
        IF keyword IN text:
            changes.APPEND(f"ç‰©å“å˜åŒ–ï¼ˆ{keyword}ï¼‰")
            BREAK
        END IF
    END FOR
    
    IF LENGTH(changes) > 0:
        RETURN {"found": TRUE, "description": JOIN(changes, "ã€")}
    ELSE:
        RETURN {"found": FALSE, "description": ""}
    END IF
END FUNCTION

FUNCTION EXTRACT_SENTENCE_WITH_WORD(text, word):
    """æå–åŒ…å«æŒ‡å®šè¯çš„å¥å­"""
    
    sentences = SPLIT_SENTENCES(text)
    
    FOR sentence IN sentences:
        IF word IN sentence:
            RETURN sentence
        END IF
    END FOR
    
    RETURN ""
END FUNCTION

FUNCTION EXTRACT_INNER_MONOLOGUE(text):
    """æå–å†…å¿ƒç‹¬ç™½"""
    
    # ç®€åŒ–å®ç°ï¼šæŸ¥æ‰¾"ä»–æƒ³""å¿ƒé‡Œ"ç­‰æ ‡å¿—
    markers = ["ä»–æƒ³", "å¥¹æƒ³", "å¿ƒé‡Œ", "å¿ƒä¸­"]
    
    FOR marker IN markers:
        pos = text.FIND(marker)
        IF pos >= 0:
            # æå–ä»æ ‡å¿—å¼€å§‹çš„50ä¸ªå­—
            snippet = text[pos:pos+50]
            RETURN snippet
        END IF
    END FOR
    
    RETURN ""
END FUNCTION
```

---

## Â§6 æ™ºèƒ½ä¿®å¤ç³»ç»Ÿ | é—®é¢˜æº¯æºä¸é‡å†™

### 6.1 ä¿®å¤å†³ç­–æ ‘

```python
FUNCTION DECIDE_FIX_OR_REWRITE(diagnosis, chapter_content, parsed_data):
    """
    å†³ç­–ï¼šä¿®å¤è¿˜æ˜¯é‡å†™
    """
    
    # è§„åˆ™1ï¼šæœ‰CRITICALæ–‡å­¦é—®é¢˜ â†’ å¿…é¡»é‡å†™
    critical_issues =FILTER(diagnosis.literary_issues, lambda issue: issue.severity == "CRITICAL")
    
	IF LENGTH(critical_issues) > 0:
    # æ£€æŸ¥é—®é¢˜æ˜¯å¦é›†ä¸­åœ¨å°‘æ•°åœºæ™¯
    problematic_scenes = []
    FOR issue IN critical_issues:
        IF "scene_idx" IN issue:
            IF issue.scene_idx NOT IN problematic_scenes:
                problematic_scenes.APPEND(issue.scene_idx)
            END IF
        END IF
    END FOR
    
    total_scenes = COUNT_SCENES(chapter_content)
    
    IF LENGTH(problematic_scenes) > 0 AND LENGTH(problematic_scenes) <= total_scenes * 0.3:
        # å°‘äº30%çš„åœºæ™¯æœ‰é—®é¢˜ â†’ éƒ¨åˆ†é‡å†™
        RETURN {
            "action": "PARTIAL_REWRITE",
            "reason": f"{LENGTH(problematic_scenes)}ä¸ªåœºæ™¯éœ€è¦é‡å†™",
            "scenes": problematic_scenes,
            "issues": critical_issues
        }
    ELSE:
        # å¤šæ•°åœºæ™¯æœ‰é—®é¢˜æˆ–å…¨å±€é—®é¢˜ â†’ å…¨éƒ¨é‡å†™
        RETURN {
            "action": "FULL_REWRITE",
            "reason": f"å­˜åœ¨{LENGTH(critical_issues)}ä¸ªCRITICALé—®é¢˜ï¼Œå½±å“èŒƒå›´å¹¿",
            "focus_areas": MAP(critical_issues, lambda i: i.type)
        }
    END IF
END IF
    
    # è§„åˆ™2ï¼šå¤šä¸ªWARNINGé—®é¢˜ â†’ å°è¯•ä¿®å¤
    warning_issues = FILTER(diagnosis.literary_issues, lambda issue: issue.severity == "WARNING")
    
    IF LENGTH(warning_issues) >= 3:
        RETURN {
            "action": "FIX",
            "reason": "å­˜åœ¨å¤šä¸ªWARNINGé—®é¢˜ï¼Œå°è¯•ä¿®å¤",
            "fixes": diagnosis.fixes
        }
    END IF
    
    # è§„åˆ™3ï¼šä»…æŠ€æœ¯æŒ‡æ ‡é—®é¢˜ â†’ ä¿®å¤
    IF LENGTH(critical_issues) == 0 AND LENGTH(warning_issues) <= 2:
        IF diagnosis.technical_metrics.word_count < 1800:
            RETURN {
                "action": "FIX",
                "reason": "å­—æ•°ç•¥å°‘ï¼Œæ‰©å……å…³é”®åœºæ™¯",
                "fixes": ["expand_scenes"]
            }
        END IF
    END IF
    
    # é»˜è®¤ï¼šé€šè¿‡
    RETURN {
        "action": "PASS",
        "reason": "æ— éœ€ä¿®å¤"
    }
END FUNCTION

FUNCTION COUNT_SCENES(text):
    """ç»Ÿè®¡ç« èŠ‚ä¸­çš„åœºæ™¯æ•°é‡ï¼ˆç®€åŒ–å®ç°ï¼‰"""
    
    # æ–¹æ³•ï¼šä»¥ç©ºè¡Œåˆ†æ®µï¼Œæ®µæ•°è¿‘ä¼¼åœºæ™¯æ•°
    paragraphs = SPLIT_PARAGRAPHS(text)
    
    # å‡è®¾æ¯3-5æ®µä¸ºä¸€ä¸ªåœºæ™¯
    estimated_scenes = MAX(1, ROUND(LENGTH(paragraphs) / 4))
    
    RETURN estimated_scenes
END FUNCTION
```

### 6.2 æ™ºèƒ½é‡å†™å¼•æ“

```python
FUNCTION INTELLIGENT_REWRITE(CAPSULE, original_plan, diagnosis):
    """
    æ™ºèƒ½é‡å†™ï¼šæ ¹æ®è¯Šæ–­ç»“æœé’ˆå¯¹æ€§é‡å†™
    
    æ ¸å¿ƒç†å¿µï¼šä¸æ˜¯å…¨éƒ¨é‡å†™ï¼Œè€Œæ˜¯å®šä½é—®é¢˜åœºæ™¯é‡å†™
    """
    
    parsed_data = PARSE_CAPSULE(CAPSULE)
    
    # STEP 1: åˆ†æé—®é¢˜æ ¹æº
    problem_analysis = ANALYZE_PROBLEM_ROOT_CAUSE(diagnosis, original_plan)
    
    # STEP 2: ç”Ÿæˆä¿®æ­£æŒ‡ä»¤
    fix_instruction = {
        "problematic_scenes": [],  # éœ€è¦é‡å†™çš„åœºæ™¯
        "adjustments": {},  # åœºæ™¯è°ƒæ•´å»ºè®®
        "focus": []  # é‡å†™é‡ç‚¹
    }
    
    FOR issue IN diagnosis.literary_issues:
        IF issue.severity == "CRITICAL":
            IF "scene_idx" IN issue:
                # å®šä½åˆ°å…·ä½“åœºæ™¯
                fix_instruction.problematic_scenes.APPEND(issue.scene_idx)
                fix_instruction.adjustments[issue.scene_idx] = {
                    "problem": issue.description,
                    "strategy": issue.fix_strategy,
                    "goal": original_plan.scenes[issue.scene_idx-1].literary_goal
                }
            ELSE:
                # å…¨å±€é—®é¢˜
                fix_instruction.focus.APPEND(issue.type)
            END IF
        END IF
    END FOR
    
    # STEP 3: é‡æ–°è§„åˆ’
    revised_plan = REVISE_PLAN(original_plan, fix_instruction, parsed_data)
    
    # STEP 4: é‡å†™é—®é¢˜åœºæ™¯
    chapter_content = ""
    monitors = INIT_MONITORS()
    
    FOR scene_plan IN revised_plan.scenes:
        IF scene_plan.scene_idx IN fix_instruction.problematic_scenes:
            # é‡å†™é—®é¢˜åœºæ™¯
            PRINT f"[REWRITE] åœºæ™¯{scene_plan.scene_idx}ï¼š{fix_instruction.adjustments[scene_plan.scene_idx].problem}"
            
            scene_text = REWRITE_SCENE_WITH_GUIDANCE(
                scene_plan,
                fix_instruction.adjustments[scene_plan.scene_idx],
                parsed_data
            )
        ELSE:
            # ä¿ç•™åŸåœºæ™¯å†™æ³•
            scene_text = WRITE_SCENE_BY_TYPE(scene_plan, parsed_data, chapter_content, monitors)
        END IF
        
        chapter_content += scene_text
        UPDATE_MONITORS(monitors, scene_text, scene_plan)
    END FOR
    
    # STEP 5: é‡æ–°è¯Šæ–­
    new_diagnosis = DIAGNOSE_LITERARY_QUALITY(chapter_content, parsed_data, revised_plan)
    
    # STEP 6: äº¤ä»˜
    new_facts = EXTRACT_FACTS(chapter_content, parsed_data)
    RETURN DELIVER_OUTPUT_V4(chapter_content, new_facts, new_diagnosis, revised_plan)
END FUNCTION
```

### 6.3 åœºæ™¯é‡å†™æŒ‡å¯¼

```python
FUNCTION REWRITE_SCENE_WITH_GUIDANCE(scene_plan, guidance, parsed_data):
    """
    æŒ‰ç…§æŒ‡å¯¼é‡å†™åœºæ™¯
    """
    
    PRINT f"[REWRITE GUIDANCE] é—®é¢˜ï¼š{guidance.problem}"
    PRINT f"[REWRITE GUIDANCE] ç­–ç•¥ï¼š{guidance.strategy}"
    PRINT f"[REWRITE GUIDANCE] ç›®æ ‡ï¼š{guidance.goal}"
    
    # æ ¹æ®ç­–ç•¥é€‰æ‹©é‡å†™æ–¹æ³•
    SWITCH guidance.strategy:
        CASE "REWRITE_CONFUSING_PARTS":
            # å¢åŠ åœºæ™¯å®šä½å’ŒåŠ¨æœºè¯´æ˜
            scene_text = WRITE_SCENE_WITH_EXTRA_CLARITY(scene_plan, parsed_data)
        
        CASE "REWRITE_SCENE":
            # å®Œå…¨é‡å†™ï¼Œç¡®ä¿è¾¾æˆç›®æ ‡
            scene_text = WRITE_SCENE_FOCUSED_ON_GOAL(scene_plan, guidance.goal, parsed_data)
        
        CASE "REWRITE_OOC_PARTS":
            # é‡å†™è§’è‰²è¡Œä¸º
            scene_text = WRITE_SCENE_RESPECTING_PERSONALITY(scene_plan, parsed_data)
        
        DEFAULT:
            # é»˜è®¤ï¼šå¸¸è§„é‡å†™
            scene_text = WRITE_SCENE_BY_TYPE(scene_plan, parsed_data, "", INIT_MONITORS())
    END SWITCH
    
    RETURN scene_text
END FUNCTION
```

---

## Â§7 è½»é‡æ¶¦è‰²å±‚ | ä»…å¤„ç†æ˜æ˜¾é—®é¢˜

### 7.1 è½»é‡æ¶¦è‰²åŸåˆ™

```python
FUNCTION LIGHT_POLISH(chapter_content, parsed_data):
    """
    è½»é‡æ¶¦è‰²ï¼šä»…å¤„ç†æ˜æ˜¾é—®é¢˜ï¼Œä¸è¿‡åº¦çŸ«æ­£
    
    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. åªåˆ é™¤æ˜æ˜¾çš„å£æ°´è¯
    2. åªä¿®å¤æ˜æ˜¾çš„æƒ…ç»ªè¯ç›´å†™
    3. ä¸å¼ºåˆ¶å‹ç¼©å†…å¿ƒæˆ
    4. ä¸å¼ºåˆ¶åˆ é™¤è§£é‡Šå¥ï¼ˆé™¤éæ˜æ˜¾å†—ä½™ï¼‰
    """
    
    polished = chapter_content
    
    # æ¶¦è‰²1ï¼šåˆ é™¤æ˜æ˜¾å£æ°´è¯ï¼ˆä»…é™é«˜é¢‘è¯ï¼‰
    obvious_fillers = ["ä¼¼ä¹", "ä»¿ä½›", "æˆ–è®¸"]
    FOR word IN obvious_fillers:
        polished = REPLACE_ALL(polished, word, "")
    END FOR
    
	# æ¶¦è‰²2ï¼šæ™ºèƒ½æ”¹å†™"æ„Ÿåˆ°XX"å¥å¼ï¼ˆè€Œéæœºæ¢°æ›¿æ¢ï¼‰
sentences = SPLIT_SENTENCES(polished)
rewritten_sentences = []

FOR i, sentence IN ENUMERATE(sentences):
    # æ£€æµ‹"æ„Ÿåˆ°XX"æ¨¡å¼
    IF MATCH(sentence, r"æ„Ÿåˆ°(éœ‡æƒŠ|ææƒ§|æ„¤æ€’)"):
        emotion = EXTRACT_EMOTION(sentence)
        
        # è·å–ä¸Šä¸‹æ–‡
        context_before = sentences[MAX(0, i-1):i]
        context_after = sentences[i+1:MIN(i+2, LENGTH(sentences))]
        
        # åˆ¤æ–­ï¼šæ˜¯å¦éœ€è¦æ”¹å†™ï¼Ÿ
        IF IS_REDUNDANT_EMOTION(sentence, context_before, context_after):
            # æ”¹å†™æ•´å¥
            rewritten = REWRITE_EMOTION_SENTENCE(sentence, emotion, context_after)
            rewritten_sentences.APPEND(rewritten)
        ELSE:
            # ä¿ç•™åŸå¥
            rewritten_sentences.APPEND(sentence)
        END IF
    ELSE:
        rewritten_sentences.APPEND(sentence)
    END IF
END FOR

polished = JOIN(rewritten_sentences, "")
    
    # æ¶¦è‰²3ï¼šåˆ é™¤æ˜æ˜¾çš„å¥—è·¯è½¬æŠ˜è¯ï¼ˆä»…é™"ç„¶è€Œ""å°±åœ¨è¿™æ—¶"ï¼‰
    polished = REPLACE_ALL(polished, "ç„¶è€Œï¼Œ", "")
    polished = REPLACE_ALL(polished, "å°±åœ¨è¿™æ—¶ï¼Œ", "")
    
    # æ¶¦è‰²4ï¼šå‹ç¼©è¶…é•¿æ®µè½ï¼ˆ>200å­—çš„æ®µè½ï¼‰
    paragraphs = SPLIT_PARAGRAPHS(polished)
    
    FOR i, para IN ENUMERATE(paragraphs):
        IF LENGTH(para) > 200:
            # å¯»æ‰¾åˆé€‚çš„åˆ†å‰²ç‚¹ï¼ˆé€—å·æˆ–å¥å·ï¼‰
            split_point = FIND_SPLIT_POINT(para, 120)
            IF split_point > 0:
                paragraphs[i] = para[:split_point] + "\n\n" + para[split_point:]
            END IF
        END IF
    END FOR
    
    polished = JOIN(paragraphs, "\n\n")
    
    RETURN CLEAN_WHITESPACE(polished)
END FUNCTION

FUNCTION EXTRACT_EMOTION(sentence):
    """ä»å¥å­ä¸­æå–æƒ…ç»ªè¯"""
    emotions = ["éœ‡æƒŠ", "ææƒ§", "æ„¤æ€’", "æ¬£å–œ", "æ‚²ä¼¤"]
    
    FOR emotion IN emotions:
        IF emotion IN sentence:
            RETURN emotion
        END IF
    END FOR
    
    RETURN "æƒ…ç»ª"
END FUNCTION

FUNCTION IS_REDUNDANT_EMOTION(sentence, before, after):
    """åˆ¤æ–­æƒ…ç»ªå¥æ˜¯å¦å†—ä½™ï¼ˆåæ–‡å·²æœ‰è§£é‡Šï¼‰"""
    
    # å¦‚æœåæ–‡æœ‰"å®Œå…¨æ²¡æƒ³åˆ°""æ€ä¹ˆå¯èƒ½"ç­‰è§£é‡Šï¼Œå‰é¢çš„"æ„Ÿåˆ°éœ‡æƒŠ"å°±å†—ä½™
    explanation_keywords = ["æ²¡æƒ³åˆ°", "æ€ä¹ˆå¯èƒ½", "ä¸æ•¢ç›¸ä¿¡", "æ„å¤–"]
    
    FOR next_sent IN after:
        IF ANY(keyword IN next_sent FOR keyword IN explanation_keywords):
            RETURN TRUE  # åæ–‡æœ‰è§£é‡Šï¼Œå‰é¢çš„æƒ…ç»ªè¯å†—ä½™
        END IF
    END FOR
    
    RETURN FALSE
END FUNCTION

FUNCTION REWRITE_EMOTION_SENTENCE(sentence, emotion, context_after):
    """æ”¹å†™æƒ…ç»ªå¥"""
    
    # ç”Ÿç†ååº”æ˜ å°„
    physiology_map = {
        "éœ‡æƒŠ": "ç³å­”éª¤ç„¶æ”¶ç¼©",
        "ææƒ§": "åèƒŒä¸€é˜µå‘å‡‰",
        "æ„¤æ€’": "å¤ªé˜³ç©´çªçªè·³åŠ¨"
    }
    
    physiology = physiology_map.GET(emotion, "å¿ƒå¤´ä¸€éœ‡")
    
    # å¦‚æœåæ–‡æœ‰è§£é‡Šï¼Œåªä¿ç•™ç”Ÿç†ååº”
    IF LENGTH(context_after) > 0:
        RETURN physiology + "ã€‚"
    ELSE:
        # åæ–‡æ— è§£é‡Šï¼Œä¿ç•™ç”Ÿç†ååº”+ç®€çŸ­å†…å¿ƒ
        RETURN physiology + f"ï¼Œè¿™æ€ä¹ˆå¯èƒ½ï¼Ÿ"
    END IF
END FUNCTION

```

---

## Â§8 äº¤ä»˜åè®® | æ¸…æ™°çš„ç»“æœå‘ˆç°

### 8.1 äº¤ä»˜æ ¼å¼

```python

FUNCTION DELIVER_OUTPUT_V4(chapter_content, new_facts, diagnosis, plan):
    """
    v4.1äº¤ä»˜æ ¼å¼ï¼šçªå‡ºæ–‡å­¦æ€§è¯„ä¼° + ç•ªèŒ„é£æ ¼æ£€æŸ¥
    """
    
    output = {
        "chapter_content": chapter_content,
        "summary": "",
        "literary_assessment": "",
        "tomato_report": "",  # æ–°å¢
        "technical_reference": "",
        "new_facts": ""
    }
    
    # ========== å¿«é€Ÿæ‘˜è¦ ==========
    status = "âœ… é€šè¿‡" IF LENGTH(diagnosis.literary_issues) == 0 ELSE "âš ï¸ å­˜åœ¨é—®é¢˜"
    
    output.summary = f"""
 ğŸ“Š åˆ›ä½œæ‘˜è¦

**çŠ¶æ€**: {status}
**å­—æ•°**: {diagnosis.technical_metrics.word_count}
**åœºæ™¯æ•°**: {LENGTH(plan.scenes)}

"""
    
    # ========== æ–‡å­¦æ€§è¯„ä¼°ï¼ˆæ ¸å¿ƒï¼‰==========
    output.literary_assessment = "## ğŸ­ æ–‡å­¦æ€§è¯„ä¼°\n\n"
    
    IF LENGTH(diagnosis.literary_issues) == 0:
        output.literary_assessment += "âœ… **æ‰€æœ‰åœºæ™¯å‡è¾¾æˆæ–‡å­¦ç›®æ ‡**\n\n"
    ELSE:
        output.literary_assessment += "### âš ï¸ éœ€è¦å…³æ³¨çš„é—®é¢˜\n\n"
        
        FOR issue IN diagnosis.literary_issues:
            severity_icon = "ğŸ”´" IF issue.severity == "CRITICAL" ELSE "ğŸŸ¡"
            output.literary_assessment += f"{severity_icon} **{issue.type}** ({issue.severity})\n"
            output.literary_assessment += f"   {issue.description}\n"
            
            IF "scene_idx" IN issue:
                output.literary_assessment += f"   åœºæ™¯ï¼š{issue.scene_idx}\n"
            END IF
            
            IF "fix_strategy" IN issue:
                output.literary_assessment += f"   å»ºè®®ï¼š{issue.fix_strategy}\n"
            END IF
            
            output.literary_assessment += "\n"
        END FOR
    END IF
    
    # è¯»è€…ä½“éªŒè¯„ä¼°
    IF "reader_experience" IN diagnosis:
        output.literary_assessment += "### ğŸ“– è¯»è€…ä½“éªŒé¢„æµ‹\n\n"
        output.literary_assessment += f"- ç†è§£åº¦ï¼š{'âœ… æ¸…æ™°' IF diagnosis.reader_experience.can_follow ELSE 'âŒ å¯èƒ½å›°æƒ‘'}\n"
        output.literary_assessment += f"- ç”»é¢æ„Ÿï¼š{diagnosis.reader_experience.GET('imagery_score', 0)}/10\n"
        output.literary_assessment += f"- æƒ…ç»ªæ›²çº¿ï¼š{'âœ… æœ‰èµ·ä¼' IF NOT diagnosis.reader_experience.GET('emotion_flat', TRUE) ELSE 'âš ï¸ å¹³æ·¡'}\n\n"
    END IF
    
    # ========== æ–°å¢ï¼šç•ªèŒ„é£æ ¼æŠ¥å‘Š ==========
    output.tomato_report = "## ğŸ… ç•ªèŒ„é£æ ¼æ£€æŸ¥\n\n"
    
    # çˆ½ç‚¹äº¤ä»˜
    cool_check = CHECK_COOL_POINT_DELIVERY(chapter_content, plan)
    output.tomato_report += f"### ğŸ’¥ çˆ½åº¦è¯„åˆ†\n"
    output.tomato_report += f"**{cool_check.coolness_score}/10** "
    
    IF cool_check.coolness_score >= 7:
        output.tomato_report += "âœ… çˆ½æ„Ÿå……è¶³\n\n"
    ELSE IF cool_check.coolness_score >= 5:
        output.tomato_report += "âš ï¸ çˆ½æ„Ÿä¸€èˆ¬\n\n"
    ELSE:
        output.tomato_report += "âŒ çˆ½æ„Ÿä¸è¶³\n\n"
    END IF
    
    IF LENGTH(cool_check.missing_cool_points) > 0:
        output.tomato_report += "**ç¼ºå¤±çˆ½ç‚¹**ï¼š\n"
        FOR missing IN cool_check.missing_cool_points:
            output.tomato_report += f"  - åœºæ™¯{missing.scene_idx}ï¼š{missing.cool_type}\n"
        END FOR
        output.tomato_report += "\n"
    ELSE:
        output.tomato_report += "âœ… æ‰€æœ‰è®¡åˆ’çˆ½ç‚¹å·²äº¤ä»˜\n\n"
    END IF
    
    # é’©å­å¯†åº¦
    hook_count = COUNT_HOOKS_IN_TEXT(chapter_content)
    total_length = diagnosis.technical_metrics.word_count
    avg_interval = total_length / MAX(hook_count, 1)
    hook_status = "âœ…" IF avg_interval <= 600 ELSE "âš ï¸"
    
    output.tomato_report += f"### ğŸ£ é’©å­å¯†åº¦\n"
    output.tomato_report += f"**{hook_count}ä¸ªé’©å­** / {total_length}å­—\n"
    output.tomato_report += f"{hook_status} å¹³å‡{avg_interval:.0f}å­—ä¸€ä¸ªé’©å­ï¼ˆæ ‡å‡†â‰¤600å­—ï¼‰\n\n"
    
    IF avg_interval > 600:
        output.tomato_report += f"âš ï¸ é’©å­é—´éš”è¿‡å¤§ï¼Œå»ºè®®åœ¨å¹³æ·¡æ®µè½å¢åŠ å¾®å†²çªæˆ–å°å‘ç°\n\n"
    END IF
    
    # ç•ªèŒ„æ ¸å¿ƒæŒ‡æ ‡
	# ç•ªèŒ„ç‰¹è‰²è¯´æ˜
	output.tomato_report += "\n> ğŸ’¡ **ç•ªèŒ„é£æ ¼ç‰¹è‰²**ï¼šçˆ½ç‚¹å¯†é›†ã€é’©å­é¢‘ç¹ã€èŠ‚å¥ç´§å‡‘ã€ä¿¡æ¯é‡å¤§\n\n"
    output.tomato_report += "### ğŸ“Š ç•ªèŒ„æ ¸å¿ƒæŒ‡æ ‡\n\n"
    output.tomato_report += "| æŒ‡æ ‡ | å½“å‰å€¼ | æ ‡å‡†èŒƒå›´ | çŠ¶æ€ |\n"
    output.tomato_report += "|------|--------|----------|------|\n"
    
    # æŒ‡æ ‡1ï¼šå¯¹è¯å æ¯”
    dialogue_ratio = diagnosis.technical_metrics.dialogue_ratio
    dialogue_status = "âœ…" IF 0.30 <= dialogue_ratio <= 0.50 ELSE "âš ï¸"
    output.tomato_report += f"| å¯¹è¯å æ¯” | {dialogue_ratio*100:.1f}% | 30-50% | {dialogue_status} |\n"
    
    # æŒ‡æ ‡2ï¼šä¿¡æ¯å¯†åº¦
    info_density = diagnosis.technical_metrics.info_density
    density_status = "âœ…" IF info_density >= 0.01 ELSE "âš ï¸"
    output.tomato_report += f"| ä¿¡æ¯å¯†åº¦ | {info_density:.3f} | â‰¥0.01 | {density_status} |\n"
    
    # æŒ‡æ ‡3ï¼šå¹³å‡æ®µè½é•¿åº¦
    avg_para = diagnosis.technical_metrics.avg_para_length
    para_status = "âœ…" IF avg_para <= 150 ELSE "âš ï¸"
    output.tomato_report += f"| å¹³å‡æ®µè½ | {avg_para:.0f}å­— | â‰¤150å­— | {para_status} |\n"
    
    output.tomato_report += "\n"
    
    # ç•ªèŒ„é£æ ¼å»ºè®®
    tomato_issues = FILTER(diagnosis.literary_issues, lambda i: i.type == "TOMATO_STYLE")
    
    IF LENGTH(tomato_issues) > 0:
        output.tomato_report += "### âš ï¸ ç•ªèŒ„é£æ ¼é—®é¢˜\n\n"
        FOR issue IN tomato_issues:
            output.tomato_report += f"- {issue.description}\n"
            IF "fix_strategy" IN issue:
                output.tomato_report += f"  ğŸ’¡ {issue.fix_strategy}\n"
            END IF
        END FOR
        output.tomato_report += "\n"
    END IF
    
    # ========== æŠ€æœ¯æŒ‡æ ‡ï¼ˆå‚è€ƒï¼‰==========
    metrics = diagnosis.technical_metrics
    
    output.technical_reference = f"""
## ğŸ“ æŠ€æœ¯æŒ‡æ ‡ï¼ˆå‚è€ƒï¼‰

| æŒ‡æ ‡ | å½“å‰å€¼ | å‚è€ƒèŒƒå›´ | çŠ¶æ€ |
|------|--------|----------|------|
| å­—æ•° | {metrics.word_count} | 2000-6000 | {'âœ…' IF 2000 <= metrics.word_count <= 6000 ELSE 'âš ï¸'} |
| å¯¹è¯å æ¯” | {metrics.dialogue_ratio*100:.1f}% | 30-50% | {'âœ…' IF 0.30 <= metrics.dialogue_ratio <= 0.50 ELSE 'ğŸ“Š'} |
| ä¿¡æ¯å¯†åº¦ | {metrics.info_density:.3f} | â‰¥0.01 | {'âœ…' IF metrics.info_density >= 0.01 ELSE 'âš ï¸'} |
| å¹³å‡æ®µè½ | {metrics.avg_para_length:.0f}å­— | â‰¤150å­— | {'âœ…' IF metrics.avg_para_length <= 150 ELSE 'ğŸ“'} |

**è¯´æ˜**ï¼šæŠ€æœ¯æŒ‡æ ‡ä»…ä¾›å‚è€ƒï¼Œä¸ä½œä¸ºè´¨é‡åˆ¤æ–­çš„å”¯ä¸€æ ‡å‡†ã€‚
"""
    
    # ========== æ–°å¢Fact ==========
    output.new_facts = FORMAT_FACTS_LIST(new_facts)
    
    # ========== åœºæ™¯ç±»å‹æŠ¥å‘Š ==========
    scene_type_report = "\n## ğŸ¬ åœºæ™¯ç±»å‹åˆ†å¸ƒ\n\n"
    
    FOR scene_plan IN plan.scenes:
        scene_type_report += f"**åœºæ™¯{scene_plan.scene_idx}** ({scene_plan.type})\n"
        scene_type_report += f"- ç›®æ ‡ï¼š{scene_plan.literary_goal}\n"
        scene_type_report += f"- å­—æ•°ï¼š{scene_plan.GET('actual_words', scene_plan.budget)}å­—\n"
        
        # æ˜¾ç¤ºçˆ½ç‚¹ï¼ˆå¦‚æœæœ‰ï¼‰
        IF scene_plan.scene_idx IN plan.GET("cool_point_plan", {}):
            cool_type = plan.cool_point_plan[scene_plan.scene_idx]
            output_icon = "ğŸ’¥"
            scene_type_report += f"- çˆ½ç‚¹ï¼š{output_icon} {cool_type}\n"
        END IF
        
        scene_type_report += "\n"
    END FOR
    
    output.summary += scene_type_report
    
    # ========== ç»„è£…æœ€ç»ˆè¾“å‡º ==========
    final_output = (
        output.summary + "\n" + 
        output.literary_assessment + "\n" + 
        output.tomato_report + "\n" +  # æ–°å¢ç•ªèŒ„æŠ¥å‘Š
        output.technical_reference + "\n" + 
        output.new_facts
    )
    
    RETURN {
        "content": chapter_content,
        "report": final_output
    }
END FUNCTION

```

---

## Â§9 å·¥å…·å‡½æ•°åº“ï¼ˆç²¾ç®€ç‰ˆï¼‰

### 9.1 æ ¸å¿ƒæ£€æŸ¥å‡½æ•°

```python
# ==================== å¯¹è¯è´¨é‡æ£€æŸ¥ ====================

FUNCTION IS_GOOD_DIALOGUE(dialogue):
    """åˆ¤æ–­å¯¹è¯æ˜¯å¦æœ‰æ•ˆï¼ˆå‚è€ƒÂ§0.3æ ‡å‡†ï¼‰"""
    
    # æ£€æŸ¥1ï¼šæ˜¯å¦æ¨è¿›å‰§æƒ…
    plot_advancing_keywords = ["å‘ç°", "å¾—åˆ°", "çŸ¥é“", "å†³å®š", "å»", "æ¥", "èµ°"]
    IF ANY(keyword IN dialogue.content FOR keyword IN plot_advancing_keywords):
        RETURN TRUE
    END IF
    
    # æ£€æŸ¥2ï¼šæ˜¯å¦æ­ç¤ºè§’è‰²
    IF LENGTH(dialogue.content) > 15:  # æœ‰å®è´¨å†…å®¹çš„å¯¹è¯
        RETURN TRUE
    END IF
    
    # æ£€æŸ¥3ï¼šæ˜¯å¦åˆ¶é€ å¼ åŠ›
    tension_keywords = ["ä½†æ˜¯", "ä¸", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "éš¾é“"]
    IF ANY(keyword IN dialogue.content FOR keyword IN tension_keywords):
        RETURN TRUE
    END IF
    
    # å¦åˆ™ï¼šæ— æ•ˆå¯¹è¯ï¼ˆå¦‚"å—¯""å•Š""å“¦"æˆ–é‡å¤ä¿¡æ¯ï¼‰
    RETURN FALSE
END FUNCTION

# ==================== ç”»é¢æ„Ÿè¯„åˆ† ====================

FUNCTION CALCULATE_IMAGERY_SCORE(text):
    """è®¡ç®—ç”»é¢æ„Ÿè¯„åˆ†ï¼ˆ0-10ï¼‰"""
    
    score = 5.0  # åŸºå‡†åˆ†
    
    # åŠ åˆ†é¡¹1ï¼šæ„Ÿå®˜è¯æ±‡
    sensory_words = ["çœ‹åˆ°", "å¬åˆ°", "é—»åˆ°", "è§¦ç¢°", "å°åˆ°", "å†°å†·", "æ¸©çƒ­", "åˆºé¼»", "æŸ”è½¯"]
    sensory_count = SUM([COUNT_OCCURRENCES(text, word) FOR word IN sensory_words])
    score += MIN(sensory_count * 0.2, 2.0)
    
    # åŠ åˆ†é¡¹2ï¼šå…·ä½“åè¯ï¼ˆè€ŒéæŠ½è±¡è¯ï¼‰
    concrete_nouns = COUNT_CONCRETE_NOUNS(text)
    abstract_nouns = COUNT_ABSTRACT_NOUNS(text)
    
    IF concrete_nouns > abstract_nouns:
        score += 1.5
    ELSE IF concrete_nouns < abstract_nouns * 0.5:
        score -= 1.5
    END IF
    
    # æ‰£åˆ†é¡¹ï¼šè¿‡å¤šçš„"ä¼¼ä¹""ä»¿ä½›"ï¼ˆæ®‹ç•™çš„æŠ½è±¡æè¿°ï¼‰
    abstract_markers = COUNT_OCCURRENCES(text, "ä¼¼ä¹") + COUNT_OCCURRENCES(text, "ä»¿ä½›")
    score -= abstract_markers * 0.3
    
    RETURN CLAMP(score, 0, 10)
END FUNCTION

# ==================== æƒ…ç»ªæ›²çº¿åˆ†æ ====================

FUNCTION ANALYZE_EMOTION_FLOW(text, parsed_data):
    """åˆ†ææƒ…ç»ªæ›²çº¿"""
    
    # åˆ†æ®µåˆ†ææƒ…ç»ª
    paragraphs = SPLIT_PARAGRAPHS(text)
    emotion_points = []
    
    FOR para IN paragraphs:
        intensity = DETECT_EMOTION_INTENSITY(para)
        emotion_points.APPEND(intensity)
    END FOR
    
    # æ£€æŸ¥æ˜¯å¦æœ‰èµ·ä¼
    max_intensity = MAX(emotion_points)
    min_intensity = MIN(emotion_points)
    
    is_flat = (max_intensity - min_intensity) < 20  # å·®å€¼<20è®¤ä¸ºå¹³æ·¡
    
    RETURN {
        "emotion_points": emotion_points,
        "is_flat": is_flat,
        "max": max_intensity,
        "min": min_intensity
    }
END FUNCTION

FUNCTION DETECT_EMOTION_INTENSITY(para):
    """æ£€æµ‹æ®µè½æƒ…ç»ªå¼ºåº¦ï¼ˆ0-100ï¼‰"""
    
    intensity = 50  # åŸºå‡†
    
    # ç”Ÿç†ååº”è¯ï¼ˆå¼ºçƒˆæƒ…ç»ªæ ‡å¿—ï¼‰
    physiology_keywords = ["å¿ƒè·³", "å‘¼å¸", "å†·æ±—", "ç³å­”", "èƒƒéƒ¨", "å‘æŠ–", "åƒµä½"]
    physiology_count = SUM([COUNT_OCCURRENCES(para, word) FOR word IN physiology_keywords])
    intensity += physiology_count * 10
    
    # åŠ¨ä½œé€Ÿåº¦è¯ï¼ˆç´§å¼ æ„Ÿæ ‡å¿—ï¼‰
    speed_keywords = ["çŒ›åœ°", "çªç„¶", "ç¬é—´", "ç«‹åˆ»", "é©¬ä¸Š"]
    speed_count = SUM([COUNT_OCCURRENCES(para, word) FOR word IN speed_keywords])
    intensity += speed_count * 8
    
    # å¯¹è¯ä¸­çš„åè½¬è¯ï¼ˆå†²çªæ ‡å¿—ï¼‰
    conflict_keywords = ["ä½†æ˜¯", "ä¸", "ä¸ºä»€ä¹ˆ", "å‡­ä»€ä¹ˆ", "ä¼‘æƒ³"]
    conflict_count = SUM([COUNT_OCCURRENCES(para, word) FOR word IN conflict_keywords])
    intensity += conflict_count * 5
    
    RETURN CLAMP(intensity, 0, 100)
END FUNCTION
```

### 9.2 è¾…åŠ©ç”Ÿæˆå‡½æ•°

```python
FUNCTION GENERATE_SENSORY_DETAILS(item, context):
    """ç”Ÿæˆæ„Ÿå®˜ç»†èŠ‚ï¼ˆä»Â§13æå–æˆ–ç”Ÿæˆï¼‰"""
    # å‚è€ƒv3.1å®ç°ï¼Œæ­¤å¤„ç®€åŒ–
    RETURN f"{item.name}çš„ç»†èŠ‚æå†™ã€‚"
END FUNCTION

FUNCTION GENERATE_CONTEXTUAL_DIALOGUE(text, insertion_point, parsed_data, target_chars):
    """ç”Ÿæˆç¬¦åˆä¸Šä¸‹æ–‡çš„å¯¹è¯"""
    # æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆåˆç†çš„å¯¹è¯
    context_before = text[MAX(0, insertion_point-200):insertion_point]
    
    # æå–å‰æ–‡æåˆ°çš„è¯é¢˜
    topic = EXTRACT_TOPIC_FROM_CONTEXT(context_before)
    
    # ç”Ÿæˆç›¸å…³å¯¹è¯
    characters = EXTRACT_NEARBY_CHARACTERS(context_before, parsed_data)
    
    IF LENGTH(characters) >= 2:
        dialogue = f""{characters[0].name}é—®é“æŸä¸ªé—®é¢˜ã€‚"\n\n"{characters[1].name}å›åº”ã€‚""
        RETURN dialogue
    ELSE:
        RETURN ""
    END IF
END FUNCTION
```

---

## Â§10 æ‰§è¡Œç¤ºä¾‹

```python
FUNCTION MAIN():
    """ä¸»ç¨‹åºå…¥å£"""
    
    PRINT """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   Claude å†™ä½œç³»ç»Ÿ v4.0 - åœºæ™¯ç±»å‹é©±åŠ¨ & æ–‡å­¦æ€§ä¼˜å…ˆ   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    
    # åŠ è½½èƒ¶å›Š
    TRY:
        CAPSULE = READ_FILE("Capsule.md")
        PRINT "[âœ“] ä¿¡æ¯èƒ¶å›ŠåŠ è½½æˆåŠŸ\n"
    CATCH FileNotFoundError:
        PRINT "[âœ—] æœªæ‰¾åˆ°Capsule.mdæ–‡ä»¶"
        RETURN
    END TRY
    
    # æ‰§è¡Œä¸»æµç¨‹
    TRY:
        result = MAIN_EXECUTION_V4(CAPSULE)
        
        # è¾“å‡ºç»“æœ
        PRINT "\n" + "="*60
        PRINT result.report
        PRINT "="*60 + "\n"
        
        PRINT "## ğŸ“ ç« èŠ‚æ­£æ–‡\n"
        PRINT result.content
        
    CATCH Exception AS e:
        PRINT f"[âœ—] æ‰§è¡Œå¤±è´¥ï¼š{e.message}"
        PRINT f"å»ºè®®ï¼š{GET_ERROR_SUGGESTION(e)}"
    END TRY
    
    PRINT "\n[âœ“] ç³»ç»Ÿæ‰§è¡Œå®Œæ¯•"
END FUNCTION

IF __name__ == "__main__":
    MAIN()
END IF
```

---

## ğŸ“‹ é™„å½•ï¼šå¿«é€Ÿå‚è€ƒå¡

### A1. åœºæ™¯ç±»å‹é€ŸæŸ¥

| ç±»å‹ | å¯¹è¯ | å†…å¿ƒç‹¬ç™½ | é‡ç‚¹ |
|------|------|----------|------|
| ç‹¬å¤„æ¢ç´¢ | 10-25% | 20-35% | ç”»é¢æ„Ÿã€å‘ç°è¿‡ç¨‹ |
| åŒäººå¯¹è¯ | 40-60% | 5-15% | å¯¹è¯æ¨è¿›å‰§æƒ… |
| ç¾¤æˆå†²çª | 45-65% | 0-10% | å¿«èŠ‚å¥ã€å†²çªå‡çº§ |
| å±æœºååº” | 15-30% | 5-15% | ç”Ÿç†ååº”ã€ç´§å¼ æ„Ÿ |
| æƒ…æ„Ÿè½¬æŠ˜ | 25-40% | 15-30% | æƒ…ç»ªé€’è¿›ã€è½¬æŠ˜ç‚¹ |

### A2. çº¦æŸä¼˜å…ˆçº§

```
P0 - RED_LINEï¼ˆç«‹å³ä¸­æ­¢ï¼‰
  â”œâ”€ OOC
  â”œâ”€ ä¸–ç•Œè§‚çŸ›ç›¾
  â””â”€ é€»è¾‘BUG

P1 - LITERARY_GOALï¼ˆé‡å†™åœºæ™¯ï¼‰
  â”œâ”€ æ ¸å¿ƒä»»åŠ¡æœªå®Œæˆ
  â”œâ”€ è§’è‰²åŠ¨æœºä¸æ˜
  â””â”€ è¯»è€…ä¼šå›°æƒ‘

P2 - QUALITY_BASELINEï¼ˆå°è¯•ä¿®å¤ï¼‰
  â”œâ”€ å­—æ•°ä¸¥é‡ä¸è¶³
  â”œâ”€ ä¿¡æ¯å¯†åº¦è¿‡ä½
  â””â”€ å¯¹è¯è´¨é‡å·®

P3 - POLISH_SUGGESTIONï¼ˆè®°å½•è­¦å‘Šï¼‰
  â”œâ”€ å¯¹è¯å æ¯”åä½
  â”œâ”€ æ®µè½è¿‡é•¿
  â””â”€ ç”»é¢æ„Ÿä¸è¶³
```

### A3. å¥½å¯¹è¯çš„ä¸‰ä¸ªæ ‡å‡†

1. **æ¨è¿›å‰§æƒ…**ï¼šæ­ç¤ºæ–°ä¿¡æ¯ã€æ”¹å˜å…³ç³»ã€è§¦å‘è¡ŒåŠ¨
2. **æ­ç¤ºè§’è‰²**ï¼šå±•ç¤ºæ€§æ ¼ã€å±•ç¤ºå†²çªã€å±•ç¤ºåœ°ä½
3. **åˆ¶é€ å¼ åŠ›**ï¼šé€ æˆè¯¯è§£ã€å‡çº§å†²çªã€åŸ‹ä¸‹ç§å­

---

**END OF SOP v4.0**

**æ ¸å¿ƒè®¾è®¡å“²å­¦æ€»ç»“**ï¼š
- æ–‡å­¦æ€§ä¼˜å…ˆï¼ŒæŠ€æœ¯æŒ‡æ ‡æœåŠ¡äºå™äº‹
- åœºæ™¯ç±»å‹é©±åŠ¨ï¼ŒåŠ¨æ€è°ƒæ•´çº¦æŸ
- é¢„è¯Šæ–­æœºåˆ¶ï¼Œé¿å…è¿”å·¥
- æ™ºèƒ½ä¿®å¤ç³»ç»Ÿï¼Œå®šä½é—®é¢˜ç²¾å‡†é‡å†™
- è¯»è€…ä½“éªŒä¸ºä¸­å¿ƒï¼Œè€Œéæœºæ¢°è¾¾æ ‡
